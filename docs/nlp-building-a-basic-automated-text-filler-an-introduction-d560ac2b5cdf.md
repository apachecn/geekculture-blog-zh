# NLP:æ„å»ºä¸€ä¸ªåŸºæœ¬çš„â€œè‡ªåŠ¨æ–‡æœ¬å¡«å……å™¨â€â€”â€”ä»‹ç»

> åŸæ–‡ï¼š<https://medium.com/geekculture/nlp-building-a-basic-automated-text-filler-an-introduction-d560ac2b5cdf?source=collection_archive---------31----------------------->

![](img/525ff2ead0a6c4e13e64e5ca9d28e2d0.png)

SOURCE: [Morioh (Website)](https://morioh.com/p/8bb5b207c3b9)

è‡ªåŠ¨æ–‡æœ¬å¡«å……å™¨æ˜¯ä¸€ä¸ªéå¸¸å—æ¬¢è¿çš„è‡ªç„¶è¯­è¨€å¤„ç†åº”ç”¨ï¼Œæ™ºèƒ½æ‰‹æœºé”®ç›˜å’Œè°·æ­Œç­‰å…¬å¸ä½¿ç”¨å®ƒæ¥é¢„æµ‹æˆ–å»ºè®®ç”¨æˆ·å°†è¾“å…¥çš„ä¸‹ä¸€ä¸ªå•è¯/çŸ­è¯­æ¥å®Œæˆä¸€ä¸ªå¥å­ã€‚å•è¯é¢„æµ‹æœ‰å¹¿æ³›çš„åº”ç”¨:

1.  åƒè°·æ­Œæœç´¢ã€Youtube è¿™æ ·çš„åº”ç”¨ç¨‹åºä½¿ç”¨å•è¯é¢„æµ‹æ¥æ¨èçƒ­é—¨æœç´¢ï¼Œè¿™å¯å‘äº†ç”¨æˆ·ï¼Œä¹ŸèŠ‚çœäº†æ—¶é—´ã€‚
2.  Gmail å’Œ Grammarly ä½¿ç”¨å•è¯é¢„æµ‹æ¥çº æ­£è¯­æ³•é”™è¯¯ï¼Œå¹¶å»ºè®®åŒä¹‰è¯ï¼Œè¿™æœ‰åŠ©äºç”¨æˆ·åœ¨æ’°å†™ç”µå­é‚®ä»¶å’Œæ–‡ç« æ—¶æ›´åŠ ä¸“ä¸šå’Œå¯Œæœ‰è¡¨ç°åŠ›ã€‚
3.  Instagramã€Twitterã€LinkedIn ç­‰åº”ç”¨ç¨‹åºä½¿ç”¨å•è¯é¢„æµ‹æ¥å»ºè®®æ ‡ç­¾ï¼Œå¸®åŠ©æé«˜ç”¨æˆ·å¸–å­çš„å¯è§æ€§ã€‚

å¯èƒ½çš„åº”ç”¨ç‚¹çš„åˆ—è¡¨æ˜¯æ— ç©·æ— å°½çš„ï¼Œè™½ç„¶å¯ä»¥ä½¿ç”¨é•¿æœŸçŸ­æœŸè®°å¿†(LSTM)ç­‰æ·±åº¦å­¦ä¹ ç®—æ³•æ¥å»ºç«‹å¤æ‚çš„æ¨¡å‹ï¼Œä½†åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ **N-Grams +é©¬å°”å¯å¤«é“¾**æ–¹æ³•æ¥å»ºç«‹ä¸€ä¸ªåŸºæœ¬çš„ä¸‹ä¸€ä¸ªå•è¯é¢„æµ‹æ¨¡å‹ã€‚

# ä»€ä¹ˆæ˜¯ N-gramï¼Ÿ

> n å…ƒè¯­æ³•æ˜¯æ¥è‡ªç»™å®šæ–‡æœ¬æˆ–è¯­éŸ³åºåˆ—çš„ n ä¸ªé¡¹ç›®çš„è¿ç»­åºåˆ—ã€‚â€”â€”ã€Definitions.net 

n-gram æ˜¯ä½ å¯ä»¥åœ¨æºæ–‡æœ¬ä¸­æ‰¾åˆ°çš„é•¿åº¦ä¸º ***n*** çš„ç›¸é‚»å•è¯æˆ–å­—æ¯çš„ç»„åˆã€‚ä¾‹å¦‚ï¼Œç»™å‡ºè¿™æ ·ä¸€å¥è¯:

> â€œç¥ä½ ç”Ÿæ—¥å¿«ä¹ï¼Œæ— åæ°â€ã€‚

è¿™å¥è¯çš„ 2 ä¸ªå­—æ¯æ˜¯:

> â€œ**ç¥ä½ **â€ã€â€œ**ç”Ÿæ—¥å¿«ä¹**â€ã€**â€œæ— åæ°**â€ã€‚

è¿™å¥è¯çš„ä¸‰ä¸ªå­—æ¯æ˜¯:

> â€**ç¥ä½ å¿«ä¹**â€œ**ç”Ÿæ—¥æ— åæ°**â€ã€‚

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸‰å…ƒæ¨¡å‹æ„å»ºä¸€ä¸ªåŸºæœ¬çš„é©¬å°”å¯å¤«é¢„æµ‹æ¨¡å‹ï¼Œä¸‰å…ƒæ¨¡å‹å°†ä» 1960 å¹´ 10 æœˆ 1 æ—¥**å°¼æ—¥åˆ©äºšç¬¬ä¸€ä»»æ€»ç†å“ˆå‰Â·é˜¿å¸ƒå·´å¡å°”Â·å¡”æ³•ç“¦Â·å·´å‹’ç“¦çˆµå£«çš„æ¼”è®²ä¸­ç”Ÿæˆã€‚**

# é©¬å°”å¯å¤«é“¾æ¦‚è¿°

é©¬å°”å¯å¤«é“¾æ˜¯ä¸€ä¸ªæ•°å­¦ç³»ç»Ÿï¼Œå®ƒæ ¹æ®æŸäº›æ¦‚ç‡è§„åˆ™ç»å†ä»ä¸€ç§çŠ¶æ€åˆ°å¦ä¸€ç§çŠ¶æ€çš„è½¬æ¢ã€‚å®ƒæ˜¯æè¿°ä¸€ç³»åˆ—å¯èƒ½äº‹ä»¶çš„éšæœºæ¨¡å‹ï¼Œå…¶ä¸­æ¯ä¸ªäº‹ä»¶çš„æ¦‚ç‡ä»…å–å†³äºå‰ä¸€ä¸ªäº‹ä»¶è¾¾åˆ°çš„çŠ¶æ€ã€‚â€” [ç»´åŸºç™¾ç§‘](https://en.wikipedia.org/wiki/Markov_chain#:~:text=A%20Markov%20chain%20is%20a,time%20Markov%20chain%20(DTMC).)

ä½¿ç”¨ N-Grams æ¨¡å‹ï¼Œåºåˆ—ä¸­çš„ä¸€ä¸ªé¡¹ç›®(ä¸€ä¸ªå•è¯)å¯ä»¥è¢«è§†ä¸ºé©¬å°”å¯å¤«çŠ¶æ€ã€‚è¿™æ„å‘³ç€ä¸€æ—¦æˆ‘ä»¬æˆåŠŸåœ°æ„å»ºäº†æ¨¡å‹ï¼Œæˆ‘ä»¬å°†èƒ½å¤Ÿæ ¹æ®ä¹‹å‰çœ‹åˆ°çš„æ•°æ®ä¸­å‡ºç°çš„å•è¯æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ã€‚

# å…¥é—¨æŒ‡å—

é¦–å…ˆï¼Œæˆ‘ä»¬å¯¼å…¥æ‰€æœ‰éœ€è¦çš„åº“ï¼Œå¹¶ä½¿ç”¨æ¼‚äº®çš„ Soup Python åº“æŠ“å–æ•°æ®(æ®µè½):

## å¯¼å…¥åº“

```
from bs4 import BeautifulSoup
from nltk.util import ngrams
from collections import defaultdict
from nltk import trigrams
from nltk.tokenize import RegexpTokenizer
import requests

*#load fetch speech text from blog*
response = requests.get("https://maxsiollun.wordpress.com/great-speeches-in-nigerias-history/")
soup = BeautifulSoup(response.text,'html.parser')
sentence = soup.find_all('p',text=True)
print(sentence[1:3])
```

## é¢„å¤„ç†æ–‡æœ¬

ä¸‹ä¸€æ­¥æ˜¯é¢„å¤„ç†æ–‡æœ¬å¹¶åˆ é™¤ä¸éœ€è¦çš„å­—ç¬¦ã€‚æˆ‘ä»¬éœ€è¦å°†æ–‡æœ¬è¾“å…¥åˆ°æ ‡è®°åˆ—è¡¨ä¸­ï¼Œå¹¶åˆ é™¤æ‰€æœ‰ç‚¹ï¼Œè¿™æ ·æ‰€æœ‰è¾“å…¥ä¸‰å…ƒè¯­æ³•æ¨¡å‹çš„æ•°æ®éƒ½æ˜¯å•è¯ã€‚

```
note=None *#we will merge the list string values into a single string*
for line **in** sentence[1:3]:
    note+=str(line)*#convert text to lower case*
sentence=note.lower()*#convert Sentence into Tokens and extract all punctuations*
tokenizer = RegexpTokenizer(r'\w+')
tk_sentence=tokenizer.tokenize(sentence)
```

## åˆ›å»ºä¸‰å…ƒæ¨¡å‹

ç°åœ¨æˆ‘ä»¬ç”Ÿæˆæˆ‘ä»¬çš„ä¸‰å…ƒæ¨¡å‹:

```
gram_sentence=list(ngrams(tk_sentence, 3))
```

## å»ºç«‹æ¨¡å‹

æœ€åï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥ä½¿ç”¨æˆ‘ä»¬çš„åˆ—è¡¨ä¸‰å…ƒç»„æ¥æ„å»ºé©¬å°”å¯å¤«æ¨¡å‹ã€‚

```
*# Create Word Model*
word_model = defaultdict(lambda: defaultdict(lambda: 0))

for sentence **in** tk_sentence:
    for first_word, second_word, word_label **in** trigrams(tk_sentence,pad_left=True,pad_right=True):
        word_model[(first_word, second_word)][word_label] += 1dict(word_model)
```

å¦‚æœä½ æƒ³è‡ªå·±å°è¯•æˆ–è€…æŸ¥çœ‹æ¨¡å‹çš„ç»“æœï¼Œå¯ä»¥æŸ¥çœ‹æˆ‘çš„ [**Kaggle ç¬”è®°æœ¬**](https://www.kaggle.com/nnitiwe/nlp-predicting-next-word) ä¸Šçš„å®Œæ•´ä»£ç ã€‚

å¯¹äºè¿™ä¸ªç‰¹å®šçš„é¢„æµ‹ï¼Œåˆ—å‡ºçš„å•è¯é›†çš„æ¦‚ç‡å¾—åˆ†æ˜¯ ***0.33*** ã€‚ç„¶è€Œï¼Œåœ¨å¾—åˆ†å¤§å°ä¸åŒçš„æƒ…å†µä¸‹ï¼Œå…·æœ‰è¾ƒé«˜å¤§å°çš„å¾—åˆ†æ˜¯æœ€ä¼˜é€‰çš„é¢„æµ‹ã€‚

![](img/7e6ee75b3be132e68248ffeff57756a6.png)

å¦‚æœä½ è§‰å¾—è¿™ä¸ªæ•™ç¨‹æœ‰å¸®åŠ©ï¼Œæ¯”å¦‚ğŸ‘ğŸ»ğŸ‘ğŸ»æ›´å¤šå†…å®¹è¯·å…³æ³¨æˆ‘ã€‚