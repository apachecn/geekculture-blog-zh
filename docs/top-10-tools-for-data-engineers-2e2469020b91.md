# 数据工程师的 10 大工具

> 原文：<https://medium.com/geekculture/top-10-tools-for-data-engineers-2e2469020b91?source=collection_archive---------5----------------------->

![](img/a803946bf558410f8b76729d220b2858.png)

云工具的增加和处理海量原始数据的需求导致对数据工程师的需求大幅增加。数据工程师构建数据管道。它们也是数据基础设施设计和算法开发的支柱。数据工程师对于让数据对公司更有用至关重要。

为了构建这样一个丰富的数据基础设施，数据工程师需要混合不同的编程语言、数据管理工具、数据仓库以及用于数据处理、数据分析和 AI/ML 的整套其他工具。

本文将重点介绍数据工程师用来构建高效数据基础设施的 10 大工具。

# 不那么秘密的数据工程工具

# 1.计算机编程语言

[Python](https://www.python.org/) 是一种流行的通用编程语言。它很容易学习，并且已经成为数据工程事实上的标准。

Python 可以被称为编程语言的瑞士军刀，因为它有多种用例，尤其是在构建数据管道方面。数据工程师使用 Python 来编写 ETL 框架、API 交互、自动化和数据管理任务，如整形、聚合、连接不同的源等。

简单的语法和丰富的第三方库是 Python 的其他优势。最重要的是，这种编程语言有助于减少开发时间，从而减少公司的开支。如今，在 T4 超过三分之二的数据工程师工作清单中，Python 是一门必须知道的编程语言。

# 2.结构化查询语言

查询是所有数据工程师的饭碗。 [SQL(结构化查询语言)](https://en.wikipedia.org/wiki/SQL)是数据工程师用来创建业务逻辑模型、执行复杂查询、提取关键性能指标、构建可重用数据结构的关键工具之一。

SQL 是最重要的工具之一，它使用查询、数据转换技术等来帮助访问、更新、插入、操作和修改数据。

# 3.一种数据库系统

PostgreSQL 是世界上最流行的开源关系数据库。PostgreSQL 受欢迎的众多原因之一是其活跃的开源社区——它也不是像 DBMS 或 MySQL 那样由公司主导的开源工具。

PostgreSQL 是轻量级的、高度灵活的、功能强大的，并且是使用对象关系模型构建的。它提供了广泛的内置和用户定义的功能，广泛的数据容量和可信的数据完整性。PostgreSQL 专为处理大型数据集而设计，同时提供高容错能力，是数据工程工作流的理想选择。

# 4.MongoDB

MongoDB 是一个流行的 NoSQL 数据库。它易于使用，高度灵活，可以存储和查询大规模的结构化和非结构化数据。NoSQL 数据库(如 MongoDB)因其处理非结构化数据的能力而广受欢迎。与模式僵化的关系数据库(SQL)不同，NoSQL 数据库灵活得多，并且以易于理解的简单形式存储数据。

分布式键值存储、面向文档的 NoSQL 功能和 MapReduce 计算功能等特性使 MongoDB 成为处理大量数据的绝佳选择。数据工程师处理许多原始的、未处理的数据，这使得 MongoDB 成为保留数据功能同时允许水平伸缩的经典选择。

# 5.阿帕奇火花

如今，企业了解捕获数据并使其在组织内快速可用的重要性。流处理允许您实时查询连续的数据流，包括传感器数据、网站上的用户活动、来自物联网设备的数据、金融贸易数据等数据。 [Apache Spark](https://spark.apache.org/) 代表了这样一个流行的流处理实现。

Apache Spark 是一个开源分析引擎，以其大规模数据处理能力而闻名，支持多种编程语言，包括 Java、Scala、R 和 Python。Spark 可以以微批处理的方式处理万亿字节的流，并使用内存缓存和优化的查询执行。

# 6.阿帕奇卡夫卡

与 Apache Spark 类似， [Apache Kafka](https://kafka.apache.org/) 是一个开源的事件流平台，具有多种应用程序，如数据同步、消息传递、实时数据流等。Apache Kafka 在构建 ELT 管道方面很受欢迎，并被广泛用作数据收集和摄取工具。

Apache Kafka 是一个简单、可靠、可扩展的高性能工具，可以将大量数据快速流入目标。

# 7.亚马逊红移

在现代数据基础设施中，数据仓库已经超越了数据存储的角色。[亚马逊红移](https://aws.amazon.com/redshift/?whats-new-cards.sort-by=item.additionalFields.postDateTime&whats-new-cards.sort-order=desc)就是一个很好的例子——它是一个完全托管的基于云的数据仓库，专为大规模数据存储和分析而设计。

Redshift 使得使用标准 SQL 跨数据仓库、操作数据库和数据湖查询和组合大量结构化和半结构化数据变得容易。它还允许数据工程师在数小时内轻松集成新的数据源，从而缩短洞察时间。

# 8.雪花

[雪花](https://www.snowflake.com/)是一个流行的基于云的数据仓库平台，为企业提供独立的存储和计算选项、对第三方工具的支持、数据克隆等等。通过轻松获取、转换和交付数据以获得更深入的见解，雪花有助于简化数据工程活动。

有了雪花，数据工程师不必担心管理基础设施、并发处理等。，可以专注于其他有价值的数据交付活动。

# 9.亚马逊雅典娜

[亚马逊雅典娜](https://aws.amazon.com/athena/?whats-new-cards.sort-by=item.additionalFields.postDateTime&whats-new-cards.sort-order=desc)是一款交互式查询工具，帮助你分析存储在亚马逊 S3(亚马逊简单存储服务)中的非结构化、半结构化和结构化数据。您可以使用标准 SQL 将 Athena 用于结构化和非结构化数据的即席查询。

Athena 是完全无服务器的，这意味着不需要管理或设置任何基础设施。使用 Athena，您不需要复杂的 ETL 作业来准备数据进行分析。这使得数据工程师或任何具有 SQL 技能的人能够很快分析大型数据集。

# 10.阿帕奇气流

随着现代数据工作流中多种云工具的出现，管理不同团队之间的数据并实现数据的全部潜力变得更加具有挑战性。作业编排和调度工具致力于消除数据孤岛、简化工作流程和自动化重复性任务，以便 IT 部门能够快速高效地开展工作。Apache Airflow 已经成为数据工程师编排和调度数据管道的常用工具。

Apache Airflow 通过高效的任务调度帮助您构建现代化的数据管道。它提供了一个丰富的用户界面，可以轻松地可视化生产中运行的管道，监控进度，并在需要时解决问题。

# 构建最佳数据工具包

这些仅仅是 10 个顶级工具。还有成吨的其他数据工具，可以让数据工程师被宠坏的选择。虽然这些工具有助于数据工程师构建高效的数据信息基础架构，但它们也各有利弊。数据工程师必须为他们的公司找到最好的数据工具，同时管理工具的缺点。最终，我们的目标是建立一个强大的堆栈，系统地处理数据，并可以在最少的调整下工作数月或数年。

# 免费注册并开始发送数据

测试我们的事件流、ELT 和反向 ETL 管道。使用我们的 HTTP 源在不到 5 分钟的时间内发送数据，或者在您的网站或应用程序中安装我们 12 个 SDK 中的一个。[入门](https://app.rudderlabs.com/signup?type=freetrial)。

这篇博客最初发表在[的新栈](https://thenewstack.io/top-10-tools-for-data-engineers/)上。