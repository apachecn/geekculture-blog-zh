# sci kit-å­¦ä¹  0.24:æ‚¨éœ€è¦äº†è§£çš„ 5 å¤§æ–°åŠŸèƒ½

> åŸæ–‡ï¼š<https://medium.com/geekculture/scikit-learn-0-24-top-5-new-features-you-need-to-know-7af15d8cdeac?source=collection_archive---------8----------------------->

![](img/5d6c3c864b2aed9ed36f1253ac3a3fa6.png)

Scikit-learn ä»ç„¶æ˜¯æœ€å—æ¬¢è¿çš„ Python å¼€æºå…è´¹æœºå™¨å­¦ä¹ åº“ä¹‹ä¸€ã€‚scikit-learn åº“åŒ…å«è®¸å¤šç”¨äºæœºå™¨å­¦ä¹ å’Œç»Ÿè®¡å»ºæ¨¡çš„æœ‰æ•ˆå·¥å…·ï¼ŒåŒ…æ‹¬åˆ†ç±»ã€å›å½’ã€èšç±»å’Œé™ç»´ã€‚

è®¸å¤šæ•°æ®ç§‘å­¦å®¶ã€æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆå’Œç ”ç©¶äººå‘˜ä¾é è¿™ä¸ªåº“è¿›è¡Œä»–ä»¬çš„[æœºå™¨å­¦ä¹ ](https://hackernoon.com/machine-learning-as-a-service-mlaas-with-sklearn-and-algorithmia-7299fbaed584?ref=hackernoon.com)é¡¹ç›®ã€‚æˆ‘ä¸ªäººå–œæ¬¢ä½¿ç”¨ scikit-learn åº“ï¼Œå› ä¸ºå®ƒæä¾›äº†å¤§é‡çš„çµæ´»æ€§ï¼Œå¹¶ä¸”å¾ˆå®¹æ˜“ç†è§£å®ƒçš„æ–‡æ¡£å’Œè®¸å¤šä¾‹å­ã€‚

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å¾ˆé«˜å…´ä¸æ‚¨åˆ†äº« scikit ä¸­çš„ 5 ä¸ªæœ€ä½³æ–°åŠŸèƒ½-learn 0.24ã€‚

# å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„ Scikit-Learn åº“

é¦–å…ˆï¼Œç¡®ä¿æ‚¨å®‰è£…äº†æœ€æ–°ç‰ˆæœ¬(å¸¦ pip):

```
pip install --upgrade scikit-learn
```

å¦‚æœæ‚¨ä½¿ç”¨ condaï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤:

```
conda install -c conda-forge scikit-learn
```

**æ³¨:**è¯¥ç‰ˆæœ¬æ”¯æŒ Python ç‰ˆæœ¬ **3.6** åˆ° **3.9** ã€‚

ç°åœ¨ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹æ–°çš„åŠŸèƒ½ï¼

# 1.å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®(MAPE)

scikit-learn çš„æ–°ç‰ˆæœ¬ä¸ºå›å½’é—®é¢˜å¼•å…¥äº†ä¸€ç§æ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼Œç§°ä¸ºå¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®(MAPE)ã€‚ä»¥å‰ä½ å¯ä»¥ç”¨ä¸€æ®µä»£ç æ¥è®¡ç®— MAPEã€‚

```
np.mean(np.abs((y_test â€” preds)/y_test))
```

ä½†æ˜¯ç°åœ¨ä½ å¯ä»¥ä» **sklearn.metrics** æ¨¡å—è°ƒç”¨ä¸€ä¸ªåä¸º**mean _ absolute _ percentage _ error**çš„å‡½æ•°æ¥è¯„ä¼°ä½ çš„å›å½’æ¨¡å‹çš„æ€§èƒ½ã€‚

**ç¤ºä¾‹:**

```
from sklearn.metrics import mean_absolute_percentage_error
y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0.0, 2, 8]
print(mean_absolute_percentage_error(y_true, y_pred))
```

0.3273809523809524

**æ³¨:**è®°ä½ï¼Œè¯¥å‡½æ•°å¹¶ä¸è¡¨ç¤ºè¾“å‡ºä¸ºèŒƒå›´[0ï¼Œ100]å†…çš„ç™¾åˆ†æ¯”ã€‚ç›¸åï¼Œæˆ‘ä»¬ç”¨èŒƒå›´[0ï¼Œ1/eps]æ¥è¡¨ç¤ºå®ƒã€‚æœ€ä½³å€¼ä¸º **0.0ã€‚**

# 2.OneHotEncoder æ”¯æŒç¼ºå¤±å€¼

[OneHotEncoder](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f?ref=hackernoon.com) ç°åœ¨å¯ä»¥å¤„ç†æ•°æ®é›†ä¸­å‡ºç°çš„ç¼ºå¤±å€¼ã€‚å®ƒå°†ç¼ºå¤±å€¼è§†ä¸ºä¸€ä¸ªç±»åˆ«ã€‚è®©æˆ‘ä»¬åœ¨ä¸‹é¢çš„ä¾‹å­ä¸­æ›´å¤šåœ°äº†è§£å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚

é¦–å…ˆå¯¼å…¥é‡è¦çš„åŒ…ã€‚

```
import pandas as pd 
import numpy as np
from sklearn.preprocessing import OneHotEncoder
```

åˆ›å»ºä¸€ä¸ªåŒ…å«ç¼ºå¤±å€¼çš„åˆ†ç±»è¦ç´ çš„ç®€å•æ•°æ®æ¡†ã€‚

```
# intialise data of lists.
data = {'education_level':['primary', 'secondary', 'bachelor', np.nan,'masters',np.nan]}

# Create DataFrame
df = pd.DataFrame(data)

# Print the output.
print(df)
```

![](img/76243b0abc38433008ef834de7451bfd.png)

å¦‚æ‚¨æ‰€è§ï¼Œåœ¨æˆ‘ä»¬çš„**æ•™è‚²æ°´å¹³**åˆ—ä¸­ï¼Œæˆ‘ä»¬ç¼ºå°‘äº†ä¸¤ä¸ªå€¼ã€‚

åˆ›å»º OneHotEncoder çš„å®ä¾‹ã€‚

```
enc = OneHotEncoder()
```

ç„¶åæ‹Ÿåˆå’Œè½¬æ¢æˆ‘ä»¬çš„æ•°æ®ã€‚

```
enc.fit_transform(df).toarray()
```

![](img/8a385b22143577e29d3c31b6eb58d0a5.png)

æˆ‘ä»¬çš„ education_level åˆ—å·²ç»è¢«è½¬æ¢ï¼Œæ‰€æœ‰ç¼ºå¤±çš„å€¼éƒ½è¢«è§†ä¸ºä¸€ä¸ªæ–°çš„ç±»åˆ«(æ£€æŸ¥ä¸Šé¢æ•°ç»„çš„æœ€åä¸€åˆ—)ã€‚

# 3.ä¸€ç§æ–°çš„ç‰¹å¾é€‰æ‹©æ–¹æ³•

**SequentialFeatureSelector**æ˜¯ scikit-learn ä¸­ä¸€ç§æ–°çš„ç‰¹å¾é€‰æ‹©æ–¹æ³•ã€‚å®ƒå¯ä»¥æ˜¯å‘å‰é€‰æ‹©ï¼Œä¹Ÿå¯ä»¥æ˜¯å‘åé€‰æ‹©ã€‚

**(ä¸€)å‰è¿›é€‰æ‹©**

å®ƒè¿­ä»£åœ°æ‰¾åˆ°æœ€ä½³æ–°ç‰¹å¾ï¼Œç„¶åå°†å…¶æ·»åŠ åˆ°æ‰€é€‰ç‰¹å¾é›†ä¸­ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬ä»é›¶ä¸ªç‰¹å¾å¼€å§‹ï¼Œç„¶åæ‰¾åˆ°ä¸€ä¸ªä½¿ä¼°è®¡é‡çš„äº¤å‰éªŒè¯åˆ†æ•°æœ€å¤§åŒ–çš„ç‰¹å¾ã€‚æ‰€é€‰ç‰¹å¾è¢«æ·»åŠ åˆ°é›†åˆä¸­ï¼Œå¹¶ä¸”é‡å¤è¯¥è¿‡ç¨‹ï¼Œç›´åˆ°æˆ‘ä»¬è¾¾åˆ°æ‰€é€‰ç‰¹å¾çš„æœŸæœ›æ•°é‡ã€‚

**(b)åå‘é€‰æ‹©**

ç¬¬äºŒæ¬¡é€‰æ‹©éµå¾ªç›¸åŒçš„æƒ³æ³•ï¼Œä½†æ–¹å‘ä¸åŒã€‚è¿™é‡Œï¼Œæˆ‘ä»¬ä»æ‰€æœ‰ç‰¹å¾å¼€å§‹ï¼Œç„¶åä»é›†åˆä¸­åˆ é™¤ä¸€ä¸ªç‰¹å¾ï¼Œç›´åˆ°æˆ‘ä»¬è¾¾åˆ°æ‰€é€‰ç‰¹å¾çš„æœŸæœ›æ•°é‡ã€‚

**ä¾‹å­**

å¯¼å…¥é‡è¦çš„åŒ…ã€‚

```
from sklearn.feature_selection import SequentialFeatureSelector
from sklearn.neighbors import KNeighborsClassifier
from sklearn.datasets import load_iris
```

åŠ è½½è™¹è†œæ•°æ®é›†åŠå…¶ç‰¹å¾åç§°ã€‚

```
X, y = load_iris(return_X_y=True, as_frame=True)
feature_names = X.columns
```

åˆ›å»ºä¼°è®¡å™¨çš„å®ä¾‹ã€‚

```
knn = KNeighborsClassifier(n_neighbors=3)
```

åˆ›å»º SequentialFeatureSelector çš„å®ä¾‹ï¼Œè®¾ç½®è¦é€‰æ‹©çš„ç‰¹å¾æ•°é‡ä¸º **2** ï¼Œè®¾ç½®æ–¹å‘ä¸ºâ€œ**å‘å**â€ã€‚

```
sfs = SequentialFeatureSelector(knn, n_features_to_select=2,direction='backward')
```

æœ€åå­¦ä¹ è¦é€‰æ‹©çš„ç‰¹æ€§ã€‚

```
sfs.fit(X,y)
```

æ˜¾ç¤ºé€‰å®šçš„åŠŸèƒ½ã€‚

```
print("Features selected by backward sequential selection: "
      f"{feature_names[sfs.get_support()].tolist()}")
```

é€šè¿‡åå‘é¡ºåºé€‰æ‹©é€‰æ‹©çš„ç‰¹å¾:['èŠ±ç“£é•¿åº¦(cm)'ï¼Œ'èŠ±ç“£å®½åº¦(cm)']

è¿™ç§æ–°çš„ç‰¹å¾é€‰æ‹©æ–¹æ³•çš„å”¯ä¸€ç¼ºç‚¹æ˜¯ï¼Œå®ƒå¯èƒ½æ¯”ä½ å·²ç»çŸ¥é“çš„å…¶ä»–æ–¹æ³•(SelectFromModel & RFE)æ…¢ï¼Œå› ä¸ºå®ƒä½¿ç”¨äº¤å‰éªŒè¯æ¥è¯„ä¼°æ¨¡å‹ã€‚

# 4.è¶…å‚æ•°è°ƒè°çš„æ–°æ–¹æ³•

è°ˆåˆ°è¶…å‚æ•°è°ƒä¼˜ï¼ŒScikit-learn çš„ GridSearchCV å’Œ RandomizedSearchCv ä¸€ç›´æ˜¯è®¸å¤šæ•°æ®ç§‘å­¦å®¶çš„é¦–é€‰ã€‚ä½†åœ¨æ–°ç‰ˆæœ¬ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸¤ä¸ªæ–°çš„è¶…å‚æ•°è°ƒæ•´ç±»ï¼Œç§°ä¸º**halvinggridsearccv**å’Œ **HalvingRandomSearchCV** ã€‚

HalvingGridSearchCV å’Œ HalvingRandomSearchCV ä½¿ç”¨ä¸€ç§ç§°ä¸º**è¿ç»­å‡åŠ**çš„æ–°æ–¹æ³•æ¥å¯»æ‰¾æœ€ä½³è¶…å‚æ•°ã€‚è¿ç»­å‡åŠå°±åƒæ‰€æœ‰è¶…å‚æ•°ç»„åˆä¹‹é—´çš„ç«äº‰æˆ–æ¯”èµ›ã€‚

**è¿ç»­å‡åŠæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ**

åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£ä¸­ï¼Œä»–ä»¬åœ¨ä¸€ä¸ªè§‚å¯Ÿå­é›†(è®­ç»ƒæ•°æ®)ä¸Šè®­ç»ƒè¶…å‚æ•°çš„ç»„åˆã€‚ç„¶ååœ¨ä¸‹ä¸€æ¬¡è¿­ä»£ä¸­ï¼Œä»…é€‰æ‹©åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£ä¸­å…·æœ‰è‰¯å¥½æ€§èƒ½çš„è¶…å‚æ•°ç»„åˆï¼Œå¹¶ä¸”å®ƒä»¬å°†åœ¨å¤§é‡è§‚å¯Ÿä¸­è¢«è®­ç»ƒä»¥ç«äº‰ã€‚

å› æ­¤ï¼Œåœ¨æ¯æ¬¡è¿­ä»£ä¸­é‡å¤è¿™ä¸ªé€‰æ‹©è¿‡ç¨‹ï¼Œç›´åˆ°åœ¨æœ€ç»ˆè¿­ä»£ä¸­é€‰æ‹©å‡ºè¶…å‚æ•°çš„æœ€ä½³ç»„åˆã€‚

æ³¨æ„:è¿™äº›è¯¾ç¨‹ä»ç„¶æ˜¯å®éªŒæ€§çš„:

**ä¾‹å¦‚:**

å¯¼å…¥é‡è¦çš„åŒ…ã€‚

```
from sklearn.datasets import make_classification
from sklearn.ensemble import RandomForestClassifier
from sklearn.experimental import enable_halving_search_cv  
from sklearn.model_selection import HalvingRandomSearchCV
from scipy.stats import randint
```

ç”±äºè¿™äº›æ–°ç±»ä»ç„¶æ˜¯å®éªŒæ€§çš„ï¼Œä¸ºäº†ä½¿ç”¨å®ƒä»¬ï¼Œæˆ‘ä»¬æ˜¾å¼åœ°å¯¼å…¥äº†**enable _ halving _ search _ cv**:

ä½¿ç”¨ make_classification æ–¹æ³•åˆ›å»ºåˆ†ç±»æ•°æ®é›†ã€‚

```
X, y = make_classification(n_samples=1000)
```

åˆ›å»ºä¼°è®¡å™¨çš„å®ä¾‹ã€‚è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨éšæœºæ£®æ—åˆ†ç±»å™¨ã€‚

```
clf = RandomForestClassifier(n_estimators=20)
```

ä¸ºè°ƒæ•´åˆ›å»ºå‚æ•°åˆ†å¸ƒã€‚

```
param_dist = {"max_depth": [3, None],
              "max_features": randint(1, 11),
              "min_samples_split": randint(2, 11),
              "bootstrap": [True, False],
              "criterion": ["gini", "entropy"]}
```

ç„¶åæˆ‘ä»¬ç”¨ RandomForestClassifier ä½œä¸ºä¼°è®¡å™¨å’Œå‚æ•°åˆ†å¸ƒåˆ—è¡¨å®ä¾‹åŒ– HalvingGridSearchCV ç±»ã€‚

```
rsh = HalvingRandomSearchCV(
    estimator=clf,
    param_distributions=param_dist,
    cv = 5,
    factor=2,
    min_resources = 20)
```

HalvingRandomSearchCV ä¸­æœ‰ä¸¤ä¸ªé‡è¦çš„å‚æ•°ä½ éœ€è¦çŸ¥é“ã€‚

(a) **å› å­** â€”è¿™å†³å®šäº†ä¸ºæ¯ä¸ªåç»­è¿­ä»£é€‰æ‹©çš„è¶…å‚æ•°ç»„åˆçš„æ¯”ä¾‹ã€‚ä¾‹å¦‚ï¼Œ ***å› å­=3*** è¡¨ç¤ºåªé€‰æ‹©ä¸‰åˆ†ä¹‹ä¸€çš„å€™é€‰è¿›è¡Œä¸‹ä¸€æ¬¡è¿­ä»£ã€‚

(b) **min_resources** æ˜¯åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£ä¸­ä¸ºæ¯ä¸ªè¶…å‚æ•°ç»„åˆåˆ†é…çš„èµ„æºé‡(è§‚å¯Ÿå€¼çš„æ•°é‡)ã€‚

æœ€åï¼Œæˆ‘ä»¬å¯ä»¥ç”¨æ•°æ®é›†æ¥æ‹Ÿåˆæˆ‘ä»¬åˆ›å»ºçš„æœç´¢å¯¹è±¡ã€‚

```
rsh.fit(X,y)
```

è®­ç»ƒåï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸åŒçš„è¾“å‡ºï¼Œå¦‚:-

(a)è¿­ä»£æ¬¡æ•°ã€‚

```
print(rsh.n_iterations_ )
```

6

(b)åœ¨æ¯æ¬¡è¿­ä»£ä¸­è¯„ä¼°çš„å€™é€‰å‚æ•°çš„æ•°é‡ã€‚

```
print(rsh.n_candidates_ )
```

**ã€50ï¼Œ25ï¼Œ13ï¼Œ7ï¼Œ4ï¼Œ2ã€‘**

(c)æ¯æ¬¡è¿­ä»£ä½¿ç”¨çš„èµ„æºæ•°é‡ã€‚

```
print(rsh.n_resources_)
```

**ã€20ï¼Œ40ï¼Œ80ï¼Œ160ï¼Œ320ï¼Œ640ã€‘**

(d)å¯¹æ‹’ç»æ•°æ®ç»™å‡ºæœ€ä½³ç»“æœçš„å‚æ•°è®¾ç½®ã€‚

```
print(rsh.best_params_)
```

**{'bootstrap': Falseï¼Œ
'criterion': 'entropy 'ï¼Œ
'max_depth': Noneï¼Œ
'max_features': 5ï¼Œ
'min_samples_split': 2}**

# 5.æ–°çš„åŠç›‘ç£å­¦ä¹ è‡ªè®­ç»ƒå…ƒä¼°è®¡å™¨

Scikit-learn 0.24 ä¸ºåŠç›‘ç£å­¦ä¹ å¼•å…¥äº†ä¸€ä¸ªæ–°çš„è‡ªæˆ‘è®­ç»ƒå®ç°ï¼Œç§°ä¸º**è‡ªæˆ‘è®­ç»ƒåˆ†ç±»å™¨**ã€‚SelfTrainingClassifier å¯ä»¥ä¸ä»»ä½•å¯ä»¥è¿”å›æ¯ä¸ªç±»çš„æ¦‚ç‡ä¼°è®¡å€¼çš„ç›‘ç£åˆ†ç±»å™¨ä¸€èµ·ä½¿ç”¨ã€‚

è¿™æ„å‘³ç€ä»»ä½•ç›‘ç£åˆ†ç±»å™¨éƒ½å¯ä»¥ä½œä¸ºåŠç›‘ç£åˆ†ç±»å™¨ï¼Œå…è®¸å®ƒä»æ•°æ®é›†ä¸­çš„æœªæ ‡è®°è§‚å¯Ÿå€¼ä¸­å­¦ä¹ ã€‚

**æ³¨æ„:**ç›®æ ‡åˆ—ä¸­æœªæ ‡è®°çš„å€¼å¿…é¡»ä¸º-1ã€‚

è®©æˆ‘ä»¬åœ¨ä¸‹é¢çš„ä¾‹å­ä¸­æ›´å¤šåœ°äº†è§£å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚

å¯¼å…¥é‡è¦çš„åŒ…

```
import numpy as np
from sklearn import datasets
from sklearn.semi_supervised import SelfTrainingClassifier
from sklearn.svm import SVC
```

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ iris æ•°æ®é›†å’Œè¶…çº§å‘é‡æœºç®—æ³•ä½œä¸ºç›‘ç£åˆ†ç±»å™¨(å®ƒå¯ä»¥å®ç° **fit** å’Œ **predict_proba** )ã€‚

ç„¶åï¼Œæˆ‘ä»¬åŠ è½½æ•°æ®é›†ï¼Œå¹¶éšæœºé€‰æ‹©ä¸€äº›æœªæ ‡è®°çš„è§‚å¯Ÿå€¼ã€‚

```
rng = np.random.RandomState(42)
iris = datasets.load_iris()
random_unlabeled_points = rng.rand(iris.target.shape[0]) < 0.3
iris.target[random_unlabeled_points] = -1
```

å¦‚æ‚¨æ‰€è§ï¼Œç›®æ ‡åˆ—ä¸­æœªæ ‡è®°çš„å€¼ä¸º-1ã€‚

![](img/cc45c48dbc2a01b8ebb595372cd3d709.png)

åˆ›å»ºç›‘ç£ä¼°è®¡å™¨çš„å®ä¾‹ã€‚

```
svc = SVC(probability=True, gamma="auto")
```

åˆ›å»ºä¸€ä¸ªè‡ªè®­ç»ƒå…ƒä¼°è®¡å™¨çš„å®ä¾‹ï¼Œå¹¶æ·»åŠ  svc ä½œä¸º base_estimatorã€‚

```
self_training_model = SelfTrainingClassifier(base_estimator=svc)
```

æœ€åï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å…·æœ‰ä¸€äº›æœªæ ‡è®°è§‚å¯Ÿå€¼çš„è™¹è†œæ•°æ®é›†ä¸Šè®­ç»ƒè‡ªè®­ç»ƒæ¨¡å‹ã€‚

```
self_training_model.fit(iris.data, iris.target)
```

è‡ªæˆ‘è®­ç»ƒåˆ†ç±»å™¨(base_estimator=SVC(gamma='auto 'ï¼Œprobability=True))

# å…³äº Scikit çš„æœ€ç»ˆæƒ³æ³•-å­¦ä¹  0.24

æ­£å¦‚æˆ‘æ‰€è¯´çš„ï¼Œscikit-learn ä»ç„¶æ˜¯æœ€å—æ¬¢è¿çš„å¼€æºæœºå™¨å­¦ä¹ åº“ä¹‹ä¸€ï¼Œæ‰€æœ‰çš„[ç‰¹æ€§](https://towardsdatascience.com/14-lesser-known-impressive-features-of-scikit-learn-library-e7ea36f1149a?ref=hackernoon.com)éƒ½å¯ä¾›æ‚¨è¿›è¡Œç«¯åˆ°ç«¯çš„æœºå™¨å­¦ä¹ é¡¹ç›®ã€‚æ‚¨è¿˜å¯ä»¥åœ¨æ‚¨çš„æœºå™¨å­¦ä¹ é¡¹ç›®ä¸­å®ç°æœ¬æ–‡ä¸­ä»‹ç»çš„ä»¤äººå°è±¡æ·±åˆ»çš„æ–°åŠŸèƒ½ã€‚

ä½ å¯ä»¥åœ¨ scikit-learn 0.24 [è¿™é‡Œ](https://scikit-learn.org/stable/auto_examples/release_highlights/plot_release_highlights_0_24_0.html?ref=hackernoon.com)æ‰¾åˆ°å‘å¸ƒçš„å…¶ä»–åŠŸèƒ½çš„äº®ç‚¹ã€‚

æ­å–œğŸ‘ğŸ‘ï¼Œä½ å·²ç»åšåˆ°è¿™ç¯‡æ–‡ç« çš„ç»“å°¾äº†ï¼æˆ‘å¸Œæœ›ä½ å­¦åˆ°äº†ä¸€äº›æ–°çš„ä¸œè¥¿ï¼Œå¯¹ä½ çš„ä¸‹ä¸€ä¸ªæœºå™¨å­¦ä¹ æˆ–æ•°æ®ç§‘å­¦é¡¹ç›®æœ‰æ‰€å¸®åŠ©ã€‚

å¦‚æœä½ å­¦åˆ°äº†æ–°çš„ä¸œè¥¿æˆ–è€…å–œæ¬¢é˜…è¯»è¿™ç¯‡æ–‡ç« ï¼Œè¯·åˆ†äº«ç»™å…¶ä»–äººçœ‹ã€‚åœ¨é‚£ä¹‹å‰ï¼Œä¸‹æœŸå¸–å­å†è§ï¼

ä½ ä¹Ÿå¯ä»¥åœ¨æ¨ç‰¹ä¸Šæ‰¾åˆ°æˆ‘ [@Davis_McDavidã€‚](https://twitter.com/Davis_McDavid?ref=hackernoon.com)

***æœ€åä¸€ä»¶äº‹:*** *åœ¨ä¸‹é¢çš„é“¾æ¥é‡Œå¤šçœ‹çœ‹ç±»ä¼¼è¿™æ ·çš„æ–‡ç« ã€‚*

[](https://towardsdatascience.com/improve-ml-model-performance-by-combining-categorical-features-a23efbb6a215) [## é€šè¿‡ç»„åˆåˆ†ç±»ç‰¹å¾æé«˜ ML æ¨¡å‹æ€§èƒ½

### æé«˜æœºå™¨å­¦ä¹ æ¨¡å‹æ€§èƒ½çš„ç®€å•æŠ€å·§ã€‚

towardsdatascience.com](https://towardsdatascience.com/improve-ml-model-performance-by-combining-categorical-features-a23efbb6a215) [](/geekculture/machine-learning-tutorial-feature-engineering-and-feature-selection-for-beginners-dd15b9d354) [## æœºå™¨å­¦ä¹ æ•™ç¨‹â€”é¢å‘åˆå­¦è€…çš„ç‰¹å¾å·¥ç¨‹å’Œç‰¹å¾é€‰æ‹©

### ä»–ä»¬è¯´æ•°æ®æ˜¯æ–°çš„çŸ³æ²¹ï¼Œä½†æˆ‘ä»¬å¹¶ä¸ç›´æ¥ä½¿ç”¨çŸ³æ²¹çš„æ¥æºã€‚å®ƒå¿…é¡»ç»è¿‡å¤„ç†å’Œæ¸…æ´—â€¦

medium.com](/geekculture/machine-learning-tutorial-feature-engineering-and-feature-selection-for-beginners-dd15b9d354) [](https://medium.datadriveninvestor.com/how-to-transform-machine-learning-models-into-native-code-with-zero-dependencies-597d01684a9f) [## å¦‚ä½•å°†æœºå™¨å­¦ä¹ æ¨¡å‹è½¬æ¢æˆé›¶ä¾èµ–çš„æœ¬æœºä»£ç 

### å°†è®­ç»ƒå¥½çš„ ML æ¨¡å‹è½¬æ¢æˆä½ é€‰æ‹©çš„ç¼–ç¨‹è¯­è¨€ã€‚

medium.datadriveninvestor.com](https://medium.datadriveninvestor.com/how-to-transform-machine-learning-models-into-native-code-with-zero-dependencies-597d01684a9f)