# å¦‚ä½•ç”¨ Snapml åŠ é€Ÿæ¨¡å‹è®­ç»ƒ

> åŸæ–‡ï¼š<https://medium.com/geekculture/how-to-speed-up-model-training-with-snapml-b2e24b546fe5?source=collection_archive---------8----------------------->

## ç”¨æ›´å°‘çš„æ—¶é—´è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹

![](img/f0f16a69eb672851bba6e4e069e6ea21.png)

[Photo by Taras Makarenko from Pexels:](https://www.pexels.com/photo/cars-ahead-on-road-593172/)

æœºå™¨å­¦ä¹ å¯¹è§£å†³å„ç§è¡Œä¸šçš„ä¸šåŠ¡é—®é¢˜æœ‰ç€å·¨å¤§çš„å½±å“ï¼ŒåŒ…æ‹¬å«ç”Ÿã€é‡‘èå’Œäº¤é€šã€‚ä½ å¯ä»¥æ”¶é›†æ¯å¤©åˆ›å»ºçš„å¤§é‡æ•°æ®ï¼Œå¹¶ä¸ºäº§å“æ¨èå’Œæƒ…æ„Ÿåˆ†æç­‰ç‰¹å®šä»»åŠ¡è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹ã€‚

å»ºè®®æ‚¨åœ¨å¤§å‹æ•°æ®é›†ä¸Šè®­ç»ƒå’Œæ‰§è¡Œå‡ ä¸ªæœºå™¨å­¦ä¹ å®éªŒï¼Œä»¥ä¾¿æ‹¥æœ‰æœ‰æ•ˆçš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚è¿™æœ‰å…¶è‡ªèº«çš„å›°éš¾ï¼Œä¾‹å¦‚éœ€è¦å¾ˆé•¿æ—¶é—´æ¥è®­ç»ƒæ¨¡å‹ä»¥è¾¾åˆ°é¢„æœŸçš„ç»“æœã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œæ‚¨å°†äº†è§£å¦‚ä½•ä½¿ç”¨ snapml python åŒ…åœ¨çŸ­æ—¶é—´å†…åŠ å¿«è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹çš„è¿‡ç¨‹ã€‚

æˆ‘ä»¬å¼€å§‹å§ï¼ğŸš€

# Snapml æ˜¯ä»€ä¹ˆï¼Ÿ

è¿™æ˜¯ IBM å¼€å‘çš„ä¸€ä¸ª python åŒ…ï¼Œç”¨äºåœ¨ CPU å’Œ GPU è®¡ç®—ç¯å¢ƒä¸­æä¾›æœºå™¨å­¦ä¹ æ¨¡å‹çš„é«˜é€Ÿè®­ç»ƒã€‚ [Snampl](https://snapml.readthedocs.io/en/latest/) å¯ä»¥å¸®åŠ©ä½ åœ¨æœºå™¨å­¦ä¹ é¡¹ç›®ä¸­å®Œæˆä»¥ä¸‹ä»»åŠ¡:-

*   åœ¨çº¿å¯¹æ–°æ•°æ®è¿›è¡Œè®­ç»ƒå’Œå†è®­ç»ƒã€‚
*   åšå¤§[å‚æ•°è°ƒè°](https://davis-david.medium.com/alternative-hyperparameter-optimization-techniques-you-need-to-know-part-1-3f68d0448fcd?source=user_profile---------35----------------------------)ã€‚
*   åšå‡ºå‡†ç¡®çš„å†³ç­–å’Œé¢„æµ‹ã€‚
*   ç”¨è¾ƒå°‘çš„èµ„æºåœ¨æ‰€æœ‰å¯ç”¨çš„æ•°æ®ä¸Šè®­ç»ƒæ¨¡å‹ã€‚
*   é«˜æ•ˆå¤„ç†å¤§æ•°æ®ã€‚

å®ƒè¿˜æ”¯æŒä¸åŒç±»å‹çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå¦‚:

*   å¹¿ä¹‰çº¿æ€§æ¨¡å‹(å¦‚çº¿æ€§å›å½’)ã€‚
*   åŸºäºæ ‘çš„æ¨¡å‹(ä¾‹å¦‚å†³ç­–æ ‘å’Œéšæœºæ£®æ—)ã€‚
*   æ¢¯åº¦å¢å‹æ¨¡å‹(ä¾‹å¦‚å¢å‹æœº)ã€‚

å½“åœ¨äº‘ç¯å¢ƒä¸­è®­ç»ƒæ¨¡å‹æ—¶ï¼ŒSnapml å¯ä»¥é€šè¿‡åŠ å¿«è®­ç»ƒè¿‡ç¨‹åœ¨çŸ­æ—¶é—´å†…å®Œæˆæ¥å¸®åŠ©æ‚¨é™ä½æˆæœ¬ã€‚

![](img/2c17fa044a0fdd8f71d1439d8a88ff9e.png)

screenshot from [https://www.zurich.ibm.com/snapml/](https://www.zurich.ibm.com/snapml/)

# å¦‚ä½•å®‰è£… Snapml

è¦å®‰è£… snapmlï¼Œè¯·åœ¨ç»ˆç«¯ä¸­è¿è¡Œä»¥ä¸‹å‘½ä»¤ã€‚

```
pip install snapml
```

**æ³¨æ„:** Snapml ç›®å‰æ”¯æŒ Python 3.7ï¼Œ3.8ï¼Œ3.9ã€‚å¯¹äº macOS ç”¨æˆ·ï¼Œç›®å‰æ”¯æŒ intel(x86_64)æ¶æ„ã€‚

# ä¸å¸¦ Snapml çš„è®­ç»ƒ ML æ¨¡å‹

åœ¨è¿™ä¸€éƒ¨åˆ†ä¸­ï¼Œæ‚¨å°†é¦–å…ˆä½¿ç”¨æ¥è‡ª [scikit-learn åº“](/geekculture/scikit-learn-1-0-new-features-in-python-machine-learning-library-d6ffea7b88dc)çš„æœºå™¨å­¦ä¹ ç®—æ³•åœ¨å¤§å‹æ•°æ®é›†ä¸Šè®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå¹¶è¯„ä¼°åœ¨æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹æ‰€ç”¨çš„æ€»æ—¶é—´ã€‚

## å¯¼å…¥åŒ…

ç¬¬ä¸€æ­¥æ˜¯å¯¼å…¥æˆ‘ä»¬å°†è¦ç”¨æ¥åŠ è½½æ•°æ®é›†ã€å‡†å¤‡æ•°æ®é›†å’Œè®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹çš„å„ç§é‡è¦ python åŒ…ã€‚

```
*#import libraris**import* numpy *as* np
*import* pandas *as* pd*from* sklearn.preprocessing *import* LabelEncoder
*from* sklearn.preprocessing *import* MinMaxScaler
*from* sklearn.ensemble *import* RandomForestClassifier
*from* sklearn.model_selection *import* cross_val_score*import* time
*import* warningswarnings.filterwarnings("ignore")
np.random.seed(123)
```

## åŠ è½½æ•°æ®é›†

æˆ‘ä»¬å°†ä½¿ç”¨é“¶è¡Œè´·æ¬¾çŠ¶æ€æ•°æ®é›†æ¥è®­ç»ƒå¯ä»¥å¯¹æœªæ¥è´·æ¬¾çŠ¶æ€è¿›è¡Œåˆ†ç±»çš„æ¨¡å‹ã€‚

ä»[kaggle.com](https://www.kaggle.com/datasets/zaurbegiev/my-dataset)ä¸‹è½½æ•°æ®é›†ã€‚

è¦åŠ è½½æ•°æ®é›†ï¼Œè¯·ä½¿ç”¨ pandas åº“ä¸­çš„ read_csv å‡½æ•°

```
*#load data*Bank_Dataset = pd.read_csv("../data/credit_train.csv")
```

æ£€æŸ¥æ•°æ®é›†çš„å‰å‡ è¡Œã€‚

```
*#show the first five rows*Bank_Dataset.head()
```

![](img/26984b41a5839b3f66c04bd27d8cc5f6.png)

Pandas Dataframe

è¯¥æ•°æ®é›†æœ‰è®¸å¤šæ˜¾ç¤ºæ¯ä¸ªå®¢æˆ·è·å¾—çš„è´·æ¬¾è¯¦ç»†ä¿¡æ¯çš„åŠŸèƒ½ã€‚

è®©æˆ‘ä»¬æ£€æŸ¥æ•°æ®é›†çš„å½¢çŠ¶ï¼Œä»¥ç¡®å®šå…¶å¤§å°ã€‚

```
# show shape
Bank_Dataset.shape
```

(100514,19)

é“¶è¡Œè´·æ¬¾çŠ¶æ€æ•°æ®é›†æœ‰è¶…è¿‡ 100ï¼Œ000 è¡Œæ•°æ®å’Œ 19 åˆ—ã€‚è¿™ä¸ªæ•°æ®é›†è¶³å¤Ÿå¤§ï¼Œå¯ä»¥è¯„ä¼°åœ¨ä½¿ç”¨å’Œä¸ä½¿ç”¨ Snapml çš„æƒ…å†µä¸‹è®­ç»ƒæ¨¡å‹æ—¶çš„æ—¶é—´å·®ã€‚

## å‡†å¤‡æ•°æ®é›†

æ‚¨éœ€è¦é€šè¿‡ç§»é™¤ä¸éœ€è¦çš„è¦ç´ ã€å¤„ç†ç¼ºå¤±å€¼å¹¶å°†æ‰€æœ‰è¦ç´ è½¬æ¢ä¸ºæ•°å€¼æ¥å‡†å¤‡æ•°æ®é›†ã€‚

**(ä¸€)ç§»é™¤ç‰¹å¾**

åœ¨è¿™ä¸€æ­¥ä¸­ï¼Œæ‚¨å°†åˆ é™¤è´·æ¬¾ ID å’Œå®¢æˆ· IDã€‚

```
#remove ID columns
Bank_Dataset.drop(["Loan ID", "Customer ID"], axis=1, inplace=True)
```

æˆ‘ä»¬ç°åœ¨å‰©ä¸‹äº† 16 ä¸ªç‰¹æ€§å’Œç›®æ ‡åˆ—(â€œè´·æ¬¾çŠ¶æ€â€)ã€‚

**(b)å¤„ç†ç¼ºå¤±å€¼**

é€šå¸¸ï¼Œæ•°æ®é›†å¯èƒ½ä¼šæœ‰ç¼ºå¤±å€¼ï¼Œæ‚¨éœ€è¦åœ¨è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹ä¹‹å‰å¤„ç†è¿™äº›ç¼ºå¤±å€¼ã€‚ä¸‹é¢æ˜¯æ£€æŸ¥æ•°æ®é›†ä¸­æ¯åˆ—ç¼ºå¤±å€¼æ•°é‡çš„ä»£ç ã€‚

```
#check missing values
Bank_Dataset.isnull().sum()
```

![](img/6948da089df7855587249c3403c324a8.png)

Features with the total number of missing values

æˆ‘ä»¬çš„æ•°æ®é›†åœ¨æ‰€æœ‰ç‰¹æ€§ä¸­éƒ½æœ‰ç¼ºå¤±å€¼ï¼ŒåŒ…æ‹¬ç›®æ ‡åˆ—(â€œè´·æ¬¾çŠ¶æ€â€)ã€‚

ä¸‹é¢çš„ä»£ç å—å°†é¦–å…ˆä½¿ç”¨æ¯ä¸ªåˆ†ç±»åˆ—ä¸­æœ€å¸¸è§çš„å€¼æ¥å¡«å……åˆ†ç±»åˆ—ä¸­ç¼ºå°‘çš„å€¼ã€‚ç„¶åé€šè¿‡ä½¿ç”¨æ¯ä¸ªæ•°å­—åˆ—çš„å¹³å‡å€¼æ¥å¡«å……æ•°å­—åˆ—ä¸­ç¼ºå°‘çš„å€¼ã€‚

```
# fill missing values for categorical features
Bank_Dataset["Loan Status"].fillna("Fully Paid", inplace=True)
Bank_Dataset["Term"].fillna("Short Term", inplace=True)
Bank_Dataset["Years in current job"].fillna("10+ years", inplace=True)
Bank_Dataset["Home Ownership"].fillna("Home Mortgage", inplace=True)
Bank_Dataset["Purpose"].fillna("Debt Consolidation", inplace=True)# fill missing values for integers features
intergers_columns = list(
    Bank_Dataset.select_dtypes(include=['floating']).columns)
for column in intergers_columns:
    Bank_Dataset[column].fillna(Bank_Dataset[column].mean(), inplace=True)
```

**(c)å˜æ¢æ•°æ®é›†**

å¤„ç†å®Œæ•°æ®é›†ä¸­çš„ç¼ºå¤±å€¼åï¼Œæ‚¨éœ€è¦å°†æ•°æ®é›†è½¬æ¢æˆæ•°å€¼ã€‚

è½¬æ¢çš„ç¬¬ä¸€æ­¥æ˜¯ä½¿ç”¨ scikit-learn åº“ä¸­çš„ LabelEncoder æ–¹æ³•é¢„å¤„ç†ä¸¤ä¸ªäºŒè¿›åˆ¶åˆ†ç±»åˆ—(Term å’Œ Loan Status)ã€‚

```
# preprocess binary categorical columnsle = LabelEncoder()
binary_columns = ["Loan Status", "Term"]
for column in binary_columns:
    Bank_Dataset[column] = le.fit_transform(Bank_Dataset[column])
```

ç„¶åï¼Œä½¿ç”¨ pandas åº“ä¸­çš„ **get_dummies** å‡½æ•°è½¬æ¢å¤šä¸ªåˆ†ç±»åˆ—ã€‚æ­¤å‡½æ•°å°†è½¬æ¢æ•°æ®é›†ä¸­çš„ä»¥ä¸‹å„åˆ—ã€‚

*   æˆ¿å±‹æ‰€æœ‰æƒ
*   ç›®çš„
*   ç›®å‰å·¥ä½œå¹´é™

```
# preprocess multiple categorical columns
Bank_Dataset = pd.get_dummies(
 Bank_Dataset,
 columns=[â€œHome Ownershipâ€, â€œPurposeâ€,â€œYears in current jobâ€])
```

**(d)åˆ†å‰²ç‰¹å¾å’Œç›®æ ‡**

å°†æ•°æ®é›†æ‹†åˆ†ä¸ºå…¶è¦ç´ åˆ—å’Œç›®æ ‡åˆ—ã€‚

```
# split data into target and features
target = Bank_Dataset["Loan Status"].values
features = Bank_Dataset.drop("Loan Status", axis=1)
```

**(e)ç¼©æ”¾ç‰¹å¾**

å˜æ¢åçš„è¦ç´ å…·æœ‰ä¸åŒçš„å€¼èŒƒå›´ã€‚æ‚¨éœ€è¦é€šè¿‡ä½¿ç”¨ scikit-learn ä¸­çš„ MimMaxScaler æ–¹æ³•å°†æ‰€æœ‰ç‰¹æ€§å½’ä¸€åŒ–åˆ°ç»™å®šçš„èŒƒå›´ 0 å’Œ 1ã€‚

```
# scaling the datasetscaler = MinMaxScaler()
features = scaler.fit_transform(features)
```

## è®­ç»ƒä¸€ä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹

è¦åœ¨æ²¡æœ‰ snapml çš„æƒ…å†µä¸‹è®­ç»ƒæ¨¡å‹ï¼Œéœ€è¦ä½¿ç”¨ä»¥ä¸‹ä»£ç ä» scikit-learn åº“ä¸­å®ä¾‹åŒ– RandomForestclassiferã€‚

```
#create a classifier
sklearn_classifier = RandomForestClassifier()
```

æœ€åï¼Œåœ¨è½¬æ¢åçš„æ•°æ®é›†ä¸Šè®­ç»ƒ RandomForestClassifierã€‚æˆ‘ä»¬è¿˜ä¼šæ‰¾åˆ°è®­ç»ƒæ¨¡å‹å‰åçš„æ—¶å·®ã€‚

```
# training classifierstart_time = time.time()scores = cross_val_score(sklearn_classifier, features, target, cv=3)print("Training Time: {}".format(time.time() - start_time))
print("Scores: {}".format(scores))
```

**è®­ç»ƒæ—¶é—´:** 55.80186605453491
**åˆ†æ•°:**ã€0.82122071ã€‘0.818827 0.82106614ã€‘

æ€»çš„æ¥è¯´ï¼Œæ¨¡å‹æ€§èƒ½çš„å‡†ç¡®åº¦çº¦ä¸º 82%ï¼Œè®­ç»ƒæ—¶é—´ä¸º **55.80 ç§’**(å‡ ä¹ 1 åˆ†é’Ÿ)ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä½¿ç”¨ Snapml æ¥åŠ é€Ÿæ¨¡å‹è®­ç»ƒã€‚

# ç”¨ Snapml è®­ç»ƒ ML æ¨¡å‹

ç¬¬ä¸€æ­¥æ˜¯ä» snapml åŒ…ä¸­å¯¼å…¥åä¸º RandomForest åˆ†ç±»å™¨çš„ç›‘ç£ç®—æ³•ã€‚

```
# add RandomForestClassifier from snapmlfrom snapml import RandomForestClassifier
```

ç„¶åå®ä¾‹åŒ–åˆ†ç±»å™¨ã€‚

```
snampl_classifier = RandomForestClassifier()
```

æœ€åä» snapml è®­ç»ƒåˆ†ç±»å™¨ï¼Œè¯„ä¼°è®­ç»ƒæ¨¡å‹å‰åçš„æ—¶é—´å·®ã€‚

```
start_time = time.time()scores = cross_val_score(snampl_classifier, features, target, cv=3)print("Training Time with snapml: {}".format(time.time() - start_time))
print("Scores: {}".format(scores))
```

ç”¨ snapml è®­ç»ƒæ—¶é—´:14.426469421387
åˆ†æ•°:[0.8106513 0.80947 0.8109181]

æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œä½¿ç”¨ snapml æ—¶çš„è®­ç»ƒæ—¶é—´æ˜¯ **14.45 ç§’**ï¼Œè¿™æ¯”ä½¿ç”¨ scikit-learn åº“è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹å‡ ä¹å¿« **4 å€**ã€‚

åœ¨äº‘ç¯å¢ƒä¸­è®­ç»ƒå¤§è§„æ¨¡æ•°æ®é›†æ—¶ï¼ŒSnapml æœ‰å¾ˆå¤§çš„æ½œåŠ›ï¼Œå¯ä»¥èŠ‚çœæ‚¨çš„æ—¶é—´å’Œæˆæœ¬ã€‚

Snapml æ”¯æŒå…¶ä»–åˆ†ç±»æ¨¡å‹ï¼Œæ‚¨å¯ä»¥åœ¨è‡ªå·±çš„æ•°æ®é›†ä¸­å°è¯•è¿™äº›æ¨¡å‹ï¼Œä¾‹å¦‚:-

*   ç‰©æµå›å½’
*   å†³ç­–æ ‘
*   æ”¯æŒå‘é‡æœº
*   å¢å‹æœº
*   æˆæ‰¹çš„æ ‘é›†åˆã€‚

# ç»“è®º

åœ¨æœ¬æ–‡ä¸­ï¼Œæ‚¨äº†è§£äº†ä½¿ç”¨å¤§å‹æ•°æ®é›†è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹çš„ä¸€äº›æŒ‘æˆ˜ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨ snampl åœ¨çŸ­æ—¶é—´å†…åŠ å¿«è®­ç»ƒæ¨¡å‹çš„è¿‡ç¨‹ã€‚

æ­£å¦‚æˆ‘ä¹‹å‰æ‰€è¯´çš„ï¼Œå¦‚æœæ‚¨åœ¨äº‘ç¯å¢ƒä¸­è®­ç»ƒæ‚¨çš„æ¨¡å‹ï¼Œsnapml ä¸ä»…ä¼šèŠ‚çœæ‚¨çš„æ—¶é—´ï¼Œè¿˜ä¼šèŠ‚çœæ‚¨çš„é‡‘é’±ã€‚è¯¥åº“å°†è®©ä½ æœ‰æœºä¼šæ‰§è¡Œå„ç§æœºå™¨å­¦ä¹ å®éªŒï¼Œè€Œä¸å¿…æ‹…å¿ƒæ—¶é—´ä¸å¤Ÿç”¨ã€‚

å¦‚æœä½ å­¦åˆ°äº†æ–°çš„ä¸œè¥¿æˆ–è€…å–œæ¬¢é˜…è¯»è¿™ç¯‡æ–‡ç« ï¼Œè¯·ä¸ä»–äººåˆ†äº«ã€‚åœ¨æ­¤ä¹‹å‰ï¼Œæ•¬è¯·å…³æ³¨ä¸‹ä¸€ç¯‡å¸–å­ï¼

ä½ ä¹Ÿå¯ä»¥åœ¨ Twitter ä¸Šæ‰¾åˆ°æˆ‘ [@Davis_McDavid](https://twitter.com/Davis_McDavid?ref=hackernoon.com) ã€‚

æœ€åä¸€ä»¶äº‹:åœ¨ä»¥ä¸‹é“¾æ¥ä¸­é˜…è¯»æ›´å¤šç±»ä¼¼çš„æ–‡ç« ã€‚

[](/geekculture/top-5-cloud-migration-strategies-you-need-to-know-fb1d92ed3c8a) [## æ‚¨éœ€è¦çŸ¥é“çš„äº”å¤§äº‘è¿ç§»ç­–ç•¥

### å¦‚ä½•å°†æ‚¨çš„æ•°æ®å’Œç³»ç»Ÿå¹³ç¨³åœ°è¿ç§»åˆ°äº‘ä¸­

medium.com](/geekculture/top-5-cloud-migration-strategies-you-need-to-know-fb1d92ed3c8a) [](https://python.plainenglish.io/how-is-web-crawling-used-in-data-science-a116d883419d) [## æ•°æ®ç§‘å­¦ä¸­å¦‚ä½•ä½¿ç”¨ Web çˆ¬è¡Œ

### ä¸ºæ‚¨çš„æ•°æ®ç§‘å­¦é¡¹ç›®æ”¶é›†æ•°æ®çš„æ— ä»£ç å·¥å…·

python .å¹³åŸè‹±è¯­. io](https://python.plainenglish.io/how-is-web-crawling-used-in-data-science-a116d883419d) [](/geekculture/top-5-reasons-why-companies-are-moving-to-the-cloud-c3a609332125) [## å…¬å¸è¿ç§»åˆ°äº‘çš„äº”å¤§åŸå› 

### ä¸ºä»€ä¹ˆä¼ä¸šå¯¹äº‘çš„é‡‡ç”¨å¢åŠ åˆ°äº† 90%

medium.com](/geekculture/top-5-reasons-why-companies-are-moving-to-the-cloud-c3a609332125)