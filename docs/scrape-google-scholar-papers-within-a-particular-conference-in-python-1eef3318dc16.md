# ç”¨ Python åœ¨ä¸€ä¸ªç‰¹å®šçš„ä¼šè®®ä¸Šæ”¶é›†è°·æ­Œå­¦æœ¯çš„è®ºæ–‡

> åŸæ–‡ï¼š<https://medium.com/geekculture/scrape-google-scholar-papers-within-a-particular-conference-in-python-1eef3318dc16?source=collection_archive---------12----------------------->

![](img/371f52c40eda7aa6e2ad42c36f00cf83.png)

# ä¼šåˆ®ä»€ä¹ˆ

![](img/1b90da0781e3079a84f1eee7bee07bab.png)

# å…ˆå†³æ¡ä»¶

**CSS é€‰æ‹©å™¨åŸºç¡€çŸ¥è¯†æŠ“å–**

CSS é€‰æ‹©å™¨å£°æ˜æ ·å¼åº”ç”¨äºæ ‡è®°çš„å“ªä¸€éƒ¨åˆ†ï¼Œä»è€Œå…è®¸ä»åŒ¹é…çš„æ ‡ç­¾å’Œå±æ€§ä¸­æå–æ•°æ®ã€‚

å¦‚æœä½ æ²¡æœ‰ä½¿ç”¨è¿‡ CSS é€‰æ‹©å™¨ï¼Œæˆ‘æœ‰ä¸€ç¯‡ä¸“é—¨çš„åšæ–‡æ˜¯å…³äº[å¦‚ä½•åœ¨æŠ“å–ç½‘é¡µæ—¶ä½¿ç”¨ CSS é€‰æ‹©å™¨](https://serpapi.com/blog/web-scraping-with-css-selectors-using-python/)çš„ï¼Œå®ƒæ¶µç›–äº†ä»€ä¹ˆæ˜¯ CSS é€‰æ‹©å™¨ï¼Œä¼˜ç‚¹å’Œç¼ºç‚¹ï¼Œä»¥åŠä¸ºä»€ä¹ˆä»æŠ“å–ç½‘é¡µçš„è§’åº¦æ¥çœ‹å®ƒä»¬å¾ˆé‡è¦ï¼Œå¹¶å±•ç¤ºäº†æŠ“å–ç½‘é¡µæ—¶ä½¿ç”¨ CSS é€‰æ‹©å™¨çš„æœ€å¸¸è§çš„æ–¹æ³•ã€‚

**å•ç‹¬çš„è™šæ‹Ÿç¯å¢ƒï¼Œå¦‚æœå®ƒå°†æ˜¯ä¸€ä¸ªé¡¹ç›®**

ç®€è€Œè¨€ä¹‹ï¼Œå®ƒåˆ›å»ºäº†ä¸€ç»„ç‹¬ç«‹çš„å·²å®‰è£…åº“ï¼ŒåŒ…æ‹¬ä¸åŒçš„ Python ç‰ˆæœ¬ï¼Œè¿™äº›ç‰ˆæœ¬å¯ä»¥åœ¨åŒä¸€ç³»ç»Ÿä¸­å…±å­˜ï¼Œä»è€Œé˜²æ­¢åº“æˆ– Python ç‰ˆæœ¬å†²çªã€‚

å¦‚æœä½ ä»¥å‰æ²¡æœ‰ä½¿ç”¨è¿‡è™šæ‹Ÿç¯å¢ƒï¼Œå¯ä»¥çœ‹çœ‹æˆ‘çš„åšå®¢æ–‡ç« ã€Šä½¿ç”¨ Virtualenv å’Œ poetiesã€‹ä¸­ä¸“é—¨çš„ [Python è™šæ‹Ÿç¯å¢ƒæ•™ç¨‹æ¥ç†Ÿæ‚‰ä¸€ä¸‹ã€‚](https://serpapi.com/blog/python-virtual-environments-using-virtualenv-and-poetry/)

ğŸ“Œæ³¨æ„:è¿™ä¸æ˜¯è¿™ç¯‡åšæ–‡çš„ä¸¥æ ¼è¦æ±‚ã€‚

**å®‰è£…åº“:**

```
pip install requests parsel google-search-results
```

**å‡å°‘è¢«å°çš„å‡ ç‡**

è¯·æ±‚æœ‰å¯èƒ½è¢«é˜»æ­¢ã€‚çœ‹çœ‹[å¦‚ä½•é™ä½æŠ“å–ç½‘é¡µæ—¶è¢«å±è”½çš„å‡ ç‡](https://serpapi.com/blog/how-to-reduce-chance-of-being-blocked-while-web/)ï¼Œæœ‰ 11 ç§æ–¹æ³•å¯ä»¥ç»•è¿‡å¤§å¤šæ•°ç½‘ç«™çš„å±è”½ã€‚

# è¿‡æ»¤çš„å·¥ä½œåŸç†

è¦è¿‡æ»¤ç»“æœï¼Œæ‚¨éœ€è¦ä½¿ç”¨ source: operatorï¼Œå®ƒå°†æœç´¢ç»“æœé™åˆ¶åœ¨åç§°ä¸­åŒ…å«â€œNIPSâ€çš„æºå‘å¸ƒçš„æ–‡æ¡£ä¸­ã€‚

è¯¥æ“ä½œç¬¦å¯ä¸ or æ“ä½œç¬¦ä¸€èµ·ä½¿ç”¨ï¼Œå³*æº:NIPS æˆ–æº:â€œç¥ç»ä¿¡æ¯â€*ã€‚å› æ­¤ï¼Œæœç´¢æŸ¥è¯¢å°†å˜æˆ:

```
search terms source:NIPS OR source:"Neural Information"
```

# å®Œæ•´ä»£ç 

# ä»£ç è§£é‡Š

æ·»åŠ ä¸€ä¸ªæ¥å—`str`çš„`list`æˆ–`str`çš„å‡½æ•°ï¼Œå¦‚æœå®ƒæ˜¯ä¸€ä¸ª`list`åˆ™è½¬æ¢å®ƒ:

```
def check_sources(source: list or str):
    if isinstance(source, str):
        return source 
    elif isinstance(source, list):
        return " OR ".join([f'source:{item}' for item in source])
```

å®šä¹‰ä¸€ä¸ªè§£æå‡½æ•°:

```
def scrape_conference_publications(query: str, source: list[str]):
    # further code...
```

*   `query: str` â€”å‘Šè¯‰ Python`query`å‚æ•°åº”è¯¥æ˜¯`string`ã€‚
*   `source: list or str` â€”å‘Šè¯‰ Python`source`å‚æ•°åº”è¯¥æ˜¯`list`æˆ–`string`ã€‚

æ£€æŸ¥æºæ˜¯å¦å¯ç”¨ï¼Œå¹¶è½¬æ¢æ”¶åˆ°çš„æºå‚æ•°:

```
if source:
    # iterates via list comprehension over recieved list of sources (strings)
    # and joins() them with " OR "
    sources = " OR ".join([f'source:{item}' for item in source]) 

# becomes: source:NIPS OR source:Neural Information, which can be used in a search query
```

åˆ›å»º URL å‚æ•°ã€ç”¨æˆ·ä»£ç†å¹¶å°†å®ƒä»¬ä¼ é€’ç»™è¯·æ±‚:

```
# [https://docs.python-requests.org/en/master/user/quickstart/#passing-parameters-in-urls](https://docs.python-requests.org/en/master/user/quickstart/#passing-parameters-in-urls)
params = {
    "q": f'{query.lower()} {sources}',  # search query
    "hl": "en",                         # language of the search
    "gl": "us"                          # country of the search
}# [https://docs.python-requests.org/en/master/user/quickstart/#custom-headers](https://docs.python-requests.org/en/master/user/quickstart/#custom-headers)
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36"
}html = requests.get("https://scholar.google.com/scholar", params=params, headers=headers, timeout=30)
selector = Selector(html.text)
```

*   [è¶…æ—¶](https://docs.python-requests.org/en/master/user/quickstart/#timeouts) â€”å‘Šè¯‰è¯·æ±‚åœ¨ 30 ç§’ååœæ­¢ç­‰å¾…å“åº”ã€‚
*   é€‰æ‹©å™¨â€”æ˜¯ä¸€ä¸ªè§£ææ•°æ®çš„ HTML/XML å¤„ç†å™¨ã€‚å–œæ¬¢ [BeautifulSoup()](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) ã€‚
*   [ç”¨æˆ·ä»£ç†](https://developer.mozilla.org/en-US/docs/Glossary/User_agent)â€”â€”ç”¨äºå……å½“â€œçœŸå®â€çš„ç”¨æˆ·è®¿é—®ã€‚é»˜è®¤è¯·æ±‚ç”¨æˆ·ä»£ç†æ˜¯ä¸€ä¸ª python-requests æ‰€ä»¥ç½‘ç«™çŸ¥é“å®ƒæ˜¯ä¸€ä¸ªå‘é€è¯·æ±‚çš„è„šæœ¬ï¼Œå¯èƒ½ä¼šé˜»æ­¢å®ƒã€‚[æ£€æŸ¥ä½ çš„ç”¨æˆ·ä»£ç†](https://www.whatismybrowser.com/detect/what-is-my-user-agent)ã€‚

åˆ›å»ºä¸€ä¸ªä¸´æ—¶åˆ—è¡¨æ¥å­˜å‚¨æ•°æ®ï¼Œå¹¶è¿­ä»£æœ‰æœºç»“æœ:

```
publications = []

for result in selector.css(".gs_r.gs_scl"):
    title = result.css(".gs_rt").xpath("normalize-space()").get()
    link = result.css(".gs_rt a::attr(href)").get()
    result_id = result.attrib["data-cid"]
    snippet = result.css(".gs_rs::text").get()
    publication_info = result.css(".gs_a").xpath("normalize-space()").get()
    cite_by_link = f'https://scholar.google.com/scholar{result.css(".gs_or_btn.gs_nph+ a::attr(href)").get()}'
    all_versions_link = f'https://scholar.google.com/scholar{result.css("a~ a+ .gs_nph::attr(href)").get()}'
    related_articles_link = f'https://scholar.google.com/scholar{result.css("a:nth-child(4)::attr(href)").get()}'
    pdf_file_title = result.css(".gs_or_ggsm a").xpath("normalize-space()").get()
    pdf_file_link = result.css(".gs_or_ggsm a::attr(href)").get()
```

*   css( <selector>) â€” [ä»ç»™å®šçš„ css é€‰æ‹©å™¨](https://github.com/scrapy/parsel/blob/90397dcd0b2c1cbb91e44f65c50f9e11628ba028/parsel/selector.py#L351-L362)ä¸­æå–æ•°æ®ã€‚åœ¨åå°ï¼Œparsel ä½¿ç”¨ cssselect å°†æ¯ä¸ª CSS æŸ¥è¯¢è½¬æ¢ä¸º XPath æŸ¥è¯¢ã€‚</selector>
*   XPath(" normalize-space()")-[è·å–ç©ºç™½æ–‡æœ¬èŠ‚ç‚¹](https://github.com/scrapy/parsel/issues/62#issuecomment-1042309376)ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œç©ºç™½æ–‡æœ¬èŠ‚ç‚¹å°†è¢«è·³è¿‡ï¼Œå¯¼è‡´ä¸å®Œæ•´çš„è¾“å‡ºã€‚
*   * text/::attr()æ˜¯ä¸€ä¸ª [parsel ä¼ªå…ƒç´ ï¼Œç”¨äºä» HTML èŠ‚ç‚¹ä¸­æå–æ–‡æœ¬æˆ–å±æ€§](https://github.com/scrapy/parsel/blob/90397dcd0b2c1cbb91e44f65c50f9e11628ba028/parsel/csstranslator.py#L48-L51)æ•°æ®ã€‚
*   get() â€”è·å–å®é™…æ•°æ®ã€‚

å°†ç»“æœä½œä¸ºå­—å…¸é™„åŠ åˆ°ä¸´æ—¶åˆ—è¡¨ï¼Œè¿”å›æˆ–æ‰“å°æå–çš„æ•°æ®:

```
publications.append({
        "result_id": result_id,
        "title": title,
        "link": link,
        "snippet": snippet,
        "publication_info": publication_info,
        "cite_by_link": cite_by_link,
        "all_versions_link": all_versions_link,
        "related_articles_link": related_articles_link,
        "pdf": {
            "title": pdf_file_title,
            "link": pdf_file_link
        }
    })

# return publicationsprint(json.dumps(publications, indent=2, ensure_ascii=False)) scrape_conference_publications(query="anatomy", source=["NIPS", "Neural Information"])
```

äº§å‡º:

```
[
  {
    "result_id": "hjgaRkq_oOEJ",
    "title": "Differential representation of arm movement direction in relation to cortical anatomy and function",
    "link": "https://iopscience.iop.org/article/10.1088/1741-2560/6/1/016006/meta",
    "snippet": "â€¦ ",
    "publication_info": "T Ball, A Schulze-Bonhage, A Aertsenâ€¦ - Journal of neural â€¦, 2009 - iopscience.iop.org",
    "cite_by_link": "https://scholar.google.com/scholar/scholar?cites=16258204980532099206&as_sdt=2005&sciodt=0,5&hl=en",
    "all_versions_link": "https://scholar.google.com/scholar/scholar?cluster=16258204980532099206&hl=en&as_sdt=0,5",
    "related_articles_link": "https://scholar.google.com/scholar/scholar?q=related:hjgaRkq_oOEJ:scholar.google.com/&scioq=anatomy+source:NIPS+OR+source:Neural+Information&hl=en&as_sdt=0,5",
    "pdf": {
      "title": "[PDF] psu.edu",
      "link": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.324.1523&rep=rep1&type=pdf"
    }
  }, ... other results
]
```

# å­¦è€…æœ‰æœºç»“æœ API

æˆ–è€…ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ SerpApi çš„[è°·æ­Œå­¦æœ¯æœ‰æœºç»“æœ API](https://serpapi.com/google-scholar-organic-results) æ¥å®ç°ã€‚

æœ€å¤§çš„åŒºåˆ«æ˜¯ï¼Œä½ ä¸éœ€è¦ä»å¤´å¼€å§‹åˆ›å»ºä¸€ä¸ªè§£æå™¨ï¼Œç»´æŠ¤å®ƒï¼Œå¼„æ¸…æ¥šå¦‚ä½•æ‰©å±•å®ƒï¼Œæœ€é‡è¦çš„æ˜¯ï¼Œå¦‚ä½•ç»•è¿‡è°·æ­Œçš„å°é”ï¼Œä»è€Œå¼„æ¸…æ¥šå¦‚ä½•è®¾ç½®ä»£ç†å’ŒéªŒè¯ç è§£å†³æ–¹æ¡ˆã€‚

```
# pip install google-search-results

import os, json
from serpapi import GoogleSearch
from urllib.parse import urlsplit, parse_qsl

params = {
    # https://docs.python.org/3/library/os.html#os.getenv
    "api_key": os.getenv("API_KEY"), # your serpapi API key
    "engine": "google_scholar",      # search engine
    "q": "AI source:NIPS",           # search query
    "hl": "en",                      # language
    # "as_ylo": "2017",              # from 2017
    # "as_yhi": "2021",              # to 2021
    "start": "0"                     # first page
    }

search = GoogleSearch(params)

publications = []

publications_is_present = True
while publications_is_present:
    results = search.get_dict()

    print(f"Currently extracting page #{results.get('serpapi_pagination', {}).get('current')}..")

    for result in results["organic_results"]:
        position = result["position"]
        title = result["title"]
        publication_info_summary = result["publication_info"]["summary"]
        result_id = result["result_id"]
        link = result.get("link")
        result_type = result.get("type")
        snippet = result.get("snippet")

        publications.append({
            "page_number": results.get("serpapi_pagination", {}).get("current"),
            "position": position + 1,
            "result_type": result_type,
            "title": title,
            "link": link,
            "result_id": result_id,
            "publication_info_summary": publication_info_summary,
            "snippet": snippet,
            })

    if "next" in results.get("serpapi_pagination", {}):
        # splits URL in parts as a dict and passes it to a GoogleSearch() class.
        search.params_dict.update(dict(parse_qsl(urlsplit(results["serpapi_pagination"]["next"]).query)))
    else:
        papers_is_present = False

print(json.dumps(organic_results_data, indent=2, ensure_ascii=False))
```

# é“¾æ¥

*   ã€the onlie IDE ä¸­çš„ä»£ç 
*   å¡å°”å¸•çš®è°·æ­Œå­¦æœ¯æœ‰æœºäº§å“ API

åŠ å…¥æˆ‘ä»¬çš„[æ¨ç‰¹](https://twitter.com/serp_api) | [YouTube](https://www.youtube.com/channel/UCUgIHlYBOD3yA3yDIRhg_mg)

æ·»åŠ ä¸€ä¸ª[ç‰¹å¾è¯·æ±‚](https://github.com/serpapi/public-roadmap/issues)ğŸ’«è¿˜æ˜¯ä¸€ä¸ª [Bug](https://github.com/serpapi/public-roadmap/issues) ğŸ