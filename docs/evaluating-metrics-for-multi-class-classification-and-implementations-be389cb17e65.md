# è¯„ä¼°å¤šç±»åˆ†ç±»å’Œå®ç°çš„åº¦é‡

> åŸæ–‡ï¼š<https://medium.com/geekculture/evaluating-metrics-for-multi-class-classification-and-implementations-be389cb17e65?source=collection_archive---------5----------------------->

![](img/c994c0a676a07b34d6689741a018196d.png)

Image from Google

è¿™ç¯‡åšå®¢æ˜¯è¿™ç¯‡æ–‡ç« çš„å»¶ç»­ã€‚

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæ‚¨å·²ç»äº†è§£äº†äºŒè¿›åˆ¶åˆ†ç±»æŒ‡æ ‡ã€‚ä»ç°åœ¨å¼€å§‹ï¼Œæˆ‘ä»¬å°†å­¦ä¹ å¤šç±»åˆ†ç±»çš„åº¦é‡ï¼Œåœ¨ä¸‹ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæ‚¨å°†å­¦ä¹ å¤šæ ‡ç­¾åˆ†ç±»åŠå…¶åº¦é‡ã€‚

å¤šç±»åˆ†ç±»æ— éæ˜¯è§£å†³ä¸€ä¸ªåˆ†ç±»é—®é¢˜ï¼Œå…¶ä¸­æˆ‘ä»¬åœ¨ç›®æ ‡åˆ—ä¸­æœ‰å¤šä¸ªç±»(ç±»çš„æ•°é‡> 2)ã€‚ä¾‹å¦‚ï¼Œå°†æ°´æœå›¾åƒåˆ†ç±»ä¸ºè‹¹æœã€æ¡”å­å’Œé¦™è•‰ã€‚

æˆ‘åœ¨è¿™é‡Œé™„ä¸Šä¸€ä¸ªç¤ºä¾‹æ•°æ®é›†ã€‚åœ¨è¯¥æ•°æ®é›†ä¸­ï¼Œå‘å±•æŒ‡æ•°åˆ—æ˜¯å…·æœ‰å¤šä¸ªç±»çš„ç›®æ ‡(ç±»çš„æ•°é‡> 2)ã€‚

æ­£å¦‚æˆ‘ä»¬åœ¨äºŒè¿›åˆ¶åˆ†ç±»åº¦é‡å­¦è¿‡çš„é‚£æ ·ï¼Œæœ‰äº†å®ƒä»¬ï¼Œæˆ‘ä»¬å°±å¯ä»¥åˆ¶å®šå¤šåˆ†ç±»åº¦é‡ã€‚

åœ¨å¤šåˆ†ç±»æŒ‡æ ‡ä¸­ï¼Œæ¯ä¸ªäºŒå…ƒåˆ†ç±»æŒ‡æ ‡æœ‰ 3 ç§å®ç°æ–¹å¼ã€‚æˆ‘å†™çš„æ—¶å€™ä½ å¯èƒ½ä¼šæ˜ç™½â€¦

å¯¹äºç²¾ç¡®äºŒè¿›åˆ¶åˆ†ç±»åº¦é‡ï¼Œåœ¨å¤šåˆ†ç±»åº¦é‡ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸‰ä¸ªç‰ˆæœ¬ï¼Œ

1.  å¾®å¹³å‡ç²¾åº¦
2.  å®è§‚å¹³å‡ç²¾åº¦
3.  åŠ æƒç²¾åº¦

ä½œä¸ºç²¾åº¦ï¼Œæˆ‘ä»¬åœ¨å¤šç±»åˆ†ç±»ä¸­æœ‰ 3 ä¸ªç‰ˆæœ¬çš„å¬å›äºŒè¿›åˆ¶åˆ†ç±»åº¦é‡ã€‚

1.  å¾®è§‚å¹³å‡å›å¿†
2.  å®è§‚å¹³å‡å›å¿†
3.  åŠ æƒå›å¿†

å¦‚ä¸Šæ‰€è¿°ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ¯ä¸ªäºŒè¿›åˆ¶åˆ†ç±»åº¦é‡åˆ†ä¸º 3 ä¸ªç‰ˆæœ¬ï¼Œå¹¶å°†å…¶å‘½åä¸ºå¤šåˆ†ç±»åº¦é‡ã€‚

ç°åœ¨ï¼Œæˆ‘å°†è®¨è®ºç²¾åº¦ï¼Œå¹¶æ·»åŠ å¬å›ä»£ç ï¼Œæ‰€æœ‰å‰©ä½™çš„æŒ‡æ ‡å°†ä»¥ç›¸åŒçš„æ–¹å¼æ„å»º(ä¸‹é¢çš„ç²¾åº¦éµå¾ªç›¸åŒçš„è¿‡ç¨‹)ã€‚åœ¨æœªæ¥çš„å¸–å­ä¸­ï¼Œæˆ‘å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•åœ¨å¤šç±»åˆ†ç±»ä¸­å½¢æˆ ROC-AUCã€‚

æ³¨æ„:-ä¸è¦è·³è¿›ä»»ä½•ä¸œè¥¿ï¼Œé™¤éä½ çŸ¥é“åŸºæœ¬çŸ¥è¯†ã€‚å› ä¸ºå®ƒå¯èƒ½ä¼šåå™¬ä½ çš„ä¿¡å¿ƒå’Œä¿¡å¿µã€‚

è®©æˆ‘ä»¬è®¨è®ºä¸€ä¸‹ precision çš„ 3 ä¸ªç‰ˆæœ¬ã€‚

1.  **å¾®å¹³å‡ç²¾åº¦:-** åœ¨è¿™é‡Œï¼Œé¦–å…ˆï¼Œæˆ‘ä»¬å°†æ‰¾åˆ°æ‰€æœ‰ç±»çš„æ‰€æœ‰çœŸé˜³æ€§ï¼Œå¹¶å°†å®ƒä»¬ç›¸åŠ ï¼Œä»¥è·å¾—æ‰€æœ‰ç±»çš„æ€»çœŸé˜³æ€§ã€‚ä¹‹åï¼Œæˆ‘ä»¬å°†æ‰¾åˆ°æ‰€æœ‰ç±»çš„æ‰€æœ‰è¯¯æŠ¥ï¼Œå¹¶å°†å®ƒä»¬ç›¸åŠ ï¼Œå¾—åˆ°æ‰€æœ‰ç±»çš„æ€»è¯¯æŠ¥ã€‚ç°åœ¨ï¼Œè®¡ç®—çœŸé˜³æ€§å’Œå‡é˜³æ€§æ€»æ•°çš„ç²¾åº¦ã€‚

2.**å®å¹³å‡ç²¾åº¦** :-è¿™é‡Œï¼Œæˆ‘ä»¬å°†æ‰¾åˆ°ç›®æ ‡åˆ—ä¸­ä¸åŒç±»çš„ç²¾åº¦ï¼Œç„¶åå¯¹å®ƒä»¬è¿›è¡Œå¹³å‡ä»¥è·å¾—æœ€ç»ˆç²¾åº¦ã€‚

3.**åŠ æƒç²¾åº¦** :-è¿™é‡Œï¼ŒåŠ æƒç²¾åº¦ä¸å®å¹³å‡ç²¾åº¦ç›¸åŒï¼Œä½†åŒºåˆ«å°±åœ¨è¿™é‡Œï¼Œå®ƒå–å†³äºæ¯ç±»ä¸­å­˜åœ¨çš„æ ·æœ¬æ•°å¹¶æ ¹æ®æ ·æœ¬æ•°è¿›è¡ŒåŠ æƒã€‚

æˆ‘çŸ¥é“ï¼Œæˆ‘å·²ç»ä¸ºæ¯ä¸€ä¸ªç»™å‡ºäº†å°çš„å®šä¹‰ï¼Œä½†è¿™å°±æ˜¯å®šä¹‰ï¼Œä»£ç è§£é‡Šäº†ä¸€åˆ‡ã€‚æ‰€ä»¥ï¼Œæ£€æŸ¥å®šä¹‰ï¼Œçœ‹çœ‹å®šä¹‰æ‰€éœ€çš„ä»£ç ï¼Œäº†è§£ä»£ç ä¸­å‘ç”Ÿäº†ä»€ä¹ˆï¼Œä½ å°±ä¼šæ˜ç™½äº‹æƒ…ã€‚

è¯·è®°ä½ï¼Œå½“æ•°æ®å¹³è¡¡æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å®è§‚ç‰ˆæœ¬ï¼Œä½†å½“æ•°æ®ä¸å¹³è¡¡æ—¶ï¼Œå¾®è§‚å’ŒåŠ æƒç‰ˆæœ¬æ›´å¯å–ã€‚

è¯·æ³¨æ„ï¼Œä¸‹é¢çš„ä»£ç ç”± precision çš„æ‰€æœ‰ 3 ä¸ªç‰ˆæœ¬ç»„æˆã€‚

```
import pandas
import argparse
import numpy
from collections import Counterfrom sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn import metrics#there are 3 Types of precision in case of Multi-class classification. 
#1\. Macro averaged precision
#2\. Micro averaged precision
#3\. Weighted precisiondef true_positive(y_true, y_pred):
    tp = 0
    for yt, yp in zip(y_true, y_pred):
        if yt == 1 and yp == 1:
            tp += 1
    return tp

def true_negative(y_true, y_pred):
    tn = 0
    for yt, yp in zip(y_true, y_pred):
        if yt == 0 and yp == 0:
            tn += 1
    return tn

def false_positive(y_true, y_pred):
    fp = 0
    for yt, yp in zip(y_true, y_pred):
        if yt == 0 and yp == 1:
            fp += 1
    return fp

def false_negative(y_true, y_pred):
    fn = 0
    for yt, yp in zip(y_true, y_pred):
        if yt == 1 and yp == 0:
            fn += 1
    return fndef precision(y_test, y_pred):
    tp =true_positive(y_test, y_pred)
    fp = false_positive(y_test, y_pred)
    try:
        return(tp/(tp+fp))
    except ZeroDivisionError:
        return 0def Macro_averaged_precision(y_test, predictions):
    precisions = []
    for i in range(1,5):
        temp_ytest = [1 if x == i else 0 for x in y_test]
        temp_ypred = [1 if x == i else 0 for x in predictions]
        print(temp_ypred)
        print(temp_ytest)
        prec = precision(temp_ytest, temp_ypred)
        precisions.append(prec)

    return (sum(precisions)/len(precisions))

def Micro_averaged_precision(y_test, predictions):
    tp = 0
    fp = 0
    for i in range(1,5):
        temp_ytest = [1 if x == i else 0 for x in y_test]
        temp_ypred = [1 if x == i else 0 for x in predictions] tp += true_positive(temp_ytest, temp_ypred)
        fp += false_positive(temp_ytest, temp_ypred) precisions = tp / (tp + fp) return precisionsdef weighted_precision(y_test, predictions):
    num_classes = len(numpy.unique(y_test))
    #coutns for every class
    precision = 0
    for i in range(1, num_classes):
        temp_ytest = [1 if x == i else 0 for x in y_test]
        temp_ypred = [1 if x == i else 0 for x in predictions] tp = true_positive(temp_ytest, temp_ypred)
        fp = false_positive(temp_ytest, temp_ypred)

        try:
            preai = tp / (tp+fp)
        except ZeroDivisionError:
            preai = 0 weighted = preai*sum(temp_ytest) precision += weighted precision = precision/len(y_test)
    return precisionif __name__ == "__main__":

    data = pandas.read_csv("C:\\Users\\iamvi\\OneDrive\\Desktop\\Metrics_in_Machine_Learning\\development-index\\Development Index.csv")

    train = data.drop(['Development Index'], axis = 1).values
    test = data["Development Index"].valuesmodel = LogisticRegression()X_train, X_test, y_train, y_test = train_test_split(train, test, stratify = test)model.fit(X_train, y_train)
    predictions = model.predict(X_test)print("Macro precision is:", Macro_averaged_precision(y_test, predictions))
    print("Micro precision is:", Micro_averaged_precision(y_test, predictions))
    print("Weighted precision is:", weighted_precision(y_test, predictions))
    print("sklearn Macro", metrics.precision_score(y_test, predictions, average = "macro"))
    print("sklearn Micro", metrics.precision_score(y_test, predictions, average = "micro"))
    print("sklearn weighted", metrics.precision_score(y_test, predictions, average = "weighted"))
```

ä½ å¯èƒ½ä¼šå‘ç°ç”±äºä»‹è´¨æ¥å£å¯¼è‡´çš„ä¸ä¸€è‡´çš„ç¼©è¿›ï¼Œå¾ˆéš¾çœ‹åˆ°ä»£ç ï¼Œç‚¹å‡»[æ­¤å¤„](https://github.com/VishnuVardhanVarapalli/Classification-Metrics/blob/main/Multi_class_classification_precision.py)æŸ¥çœ‹ Github ä¸­çš„ä»£ç ã€‚

è¿™å°±æ˜¯æ‰€æœ‰å¤šç±»åˆ†ç±»åº¦é‡æ˜¯å¦‚ä½•ä»äºŒè¿›åˆ¶åˆ†ç±»åº¦é‡äº§ç”Ÿçš„ã€‚

æ­£å¦‚æˆ‘æ‰€è¯´çš„ï¼Œæˆ‘ä¼šç»™ä½ çš„ä»£ç å¬å›ç±»ä¼¼ç²¾åº¦ï¼Œä»¥åŠæ‰€æœ‰å…¶ä½™çš„æŒ‡æ ‡ã€‚

```
import pandas
import argparse
import numpy
from collections import Counterfrom sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn import metrics#there are 3 Types of recall in case of Multi-class classification. 
#1\. Macro averaged recall
#2\. Micro averaged recall
#3\. Weighted recalldef true_positive(y_true, y_pred):
    tp = 0
    for yt, yp in zip(y_true, y_pred):
        if yt == 1 and yp == 1:
            tp += 1
    return tp

def true_negative(y_true, y_pred):
    tn = 0
    for yt, yp in zip(y_true, y_pred):
        if yt == 0 and yp == 0:
            tn += 1
    return tn

def false_positive(y_true, y_pred):
    fp = 0
    for yt, yp in zip(y_true, y_pred):
        if yt == 0 and yp == 1:
            fp += 1
    return fp

def false_negative(y_true, y_pred):
    fn = 0
    for yt, yp in zip(y_true, y_pred):
        if yt == 1 and yp == 0:
            fn += 1
    return fndef recall(y_test, y_pred):
    tp = true_positive(y_test, y_pred)
    fn = false_negative(y_test, y_pred)
    return(tp/(tp+fn))def Macro_averaged_recall(y_test, predictions):
    recalls = []
    for i in range(1,5):
        temp_ytest = [1 if x == i else 0 for x in y_test]
        temp_ypred = [1 if x == i else 0 for x in predictions]
        print(temp_ypred)
        print(temp_ytest)
        rec = recall(temp_ytest, temp_ypred)
        recalls.append(rec)

    return (sum(recalls)/len(recalls))

def Micro_averaged_recall(y_test, predictions):
    tp = 0
    tn = 0
    for i in range(1,5):
        temp_ytest = [1 if x == i else 0 for x in y_test]
        temp_ypred = [1 if x == i else 0 for x in predictions] tp += true_positive(temp_ytest, temp_ypred)
        tn += true_negative(temp_ytest, temp_ypred) recall = tp / (tp + tn) return recalldef weighted_recall(y_test, predictions):
    num_classes = len(numpy.unique(y_test))
    #counts for every class
    recall = 0
    for i in range(1, num_classes):
        temp_ytest = [1 if x == i else 0 for x in y_test]
        temp_ypred = [1 if x == i else 0 for x in predictions]tp = true_positive(temp_ytest, temp_ypred)
        tn = true_negative(temp_ytest, temp_ypred)

        try:
            rec = tp / (tp+tn)
        except ZeroDivisionError:
            rec = 0weighted = rec*sum(temp_ytest)recall += weightedrecall = recall/len(y_test)
    return recallif __name__ == "__main__":

    data = pandas.read_csv("C:\\Users\\iamvi\\OneDrive\\Desktop\\Metrics_in_Machine_Learning\\development-index\\Development Index.csv")

    train = data.drop(['Development Index'], axis = 1).values
    test = data["Development Index"].valuesmodel = LogisticRegression()X_train, X_test, y_train, y_test = train_test_split(train, test, stratify = test)model.fit(X_train, y_train)
    predictions = model.predict(X_test)print("Macro recall is:", Macro_averaged_recall(y_test, predictions))
    print("Micro recall is:", Micro_averaged_recall(y_test, predictions))
    print("Weighted recall is:", weighted_recall(y_test, predictions))
    print("sklearn Macro", metrics.recall_score(y_test, predictions, average = "macro"))
    print("sklearn Micro", metrics.recall_score(y_test, predictions, average = "micro"))
    print("sklearn weighted", metrics.recall_score(y_test, predictions, average = "weighted"))
```

precision çš„ 3 ä¸ªç‰ˆæœ¬çš„å®šä¹‰ä¹Ÿå°†åº”ç”¨äºå¬å›ã€‚

å½“ä½ åœ¨ 3 ä¸ªç‰ˆæœ¬ä¸­å®ç°äº†æˆ‘ä¸Šé¢æ‰€è¯´çš„æ‰€æœ‰å¤šç±»åˆ†ç±»åº¦é‡æ ‡å‡†ä¹‹åï¼Œä½ å¯ä»¥è‡ªä¿¡åœ°è¯´â€œæˆ‘çŸ¥é“å¤šç±»åˆ†ç±»â€ã€‚ğŸ˜‰

æ£€æŸ¥[åˆ†ç±»-åº¦é‡åº“](https://github.com/VishnuVardhanVarapalli/Classification-Metrics)ä»¥è·å¾—æˆ‘è§£é‡Šçš„æ‰€æœ‰æ¦‚å¿µçš„ä»£ç ã€‚å½“æˆ‘åœ¨è¿™é‡Œå†™æ–‡ç« æ—¶ï¼ŒGitHub å°†ä¼šæ›´æ–°ä»£ç ã€‚æ‰€ä»¥ï¼ŒæŠŠå‰å­æ”¾åœ¨ä¸Šé¢ã€‚

å¦‚æœä½ æƒ³åœ¨è¿™é‡Œè¡¥å……ä»€ä¹ˆï¼Œæˆ–è€…æƒ³è®©æˆ‘è§£é‡Šè¿™é‡Œé—æ¼çš„æ¦‚å¿µï¼Œè®©æˆ‘ä»[è¿™é‡Œ](https://iamvishnuvarapally.wixsite.com/port-folio)çŸ¥é“ã€‚

å¯ä»¥åœ¨ä¸åŒå¹³å° [LinkedIn](https://www.linkedin.com/in/vishnu-vardhan-varapalli-b6b454150/) ã€ [Github](https://github.com/VishnuVardhanVarapalli) ã€ [medium](https://iamvishnu-varapally.medium.com/) å…³æ³¨æˆ‘ã€‚

å¿«ä¹çš„ LearningâœŒ.