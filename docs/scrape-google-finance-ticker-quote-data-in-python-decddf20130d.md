# ç”¨ Python æŠ“å– Google é‡‘èè‚¡ç¥¨æŠ¥ä»·æ•°æ®

> åŸæ–‡ï¼š<https://medium.com/geekculture/scrape-google-finance-ticker-quote-data-in-python-decddf20130d?source=collection_archive---------9----------------------->

![](img/189a3166c36b83aa9c8652f3d582c9fc.png)

*   [ä¼šåˆ®ä»€ä¹ˆ](#edc4)
*   [å…ˆå†³æ¡ä»¶](#bf60)
*   [æŠ“å–è°·æ­Œè´¢ç»è‚¡ç¥¨æŠ¥ä»·æ•°æ®](#775f)
*   [æå–è·‘é©¬ç¯æ•°æ®çš„è¯´æ˜](#d39b)
*   [æ”¶é›†å¤šä¸ªè°·æ­Œé‡‘èæŠ¥ä»·](#85f0)
*   [æå–è°·æ­Œè´¢ç»å›¾è¡¨æ—¶åºæ•°æ®](#fa37)
*   [æŠ“å–è°·æ­Œè´¢ç»æ—¶åºæ•°æ®](#d172)
*   [æ—¶åºæå–ä»£ç è¯´æ˜](#30f9)
*   [çº³æ–¯è¾¾å…‹åˆ©ç‡é™åˆ¶](#4891)
*   [å…¶ä»–çº³æ–¯è¾¾å…‹ API èµ„æº](#c1bc)
*   [é“¾æ¥](#94ce)
*   [Outro](#30d0)

# ä¼šåˆ®ä»€ä¹ˆ

![](img/00b33df873941ae7b51ccfa273a0c24a.png)

# å…ˆå†³æ¡ä»¶

**CSS é€‰æ‹©å™¨åŸºç¡€çŸ¥è¯†æŠ“å–**

CSS é€‰æ‹©å™¨å£°æ˜æ ·å¼åº”ç”¨äºæ ‡è®°çš„å“ªä¸€éƒ¨åˆ†ï¼Œä»è€Œå…è®¸ä»åŒ¹é…çš„æ ‡ç­¾å’Œå±æ€§ä¸­æå–æ•°æ®ã€‚

å¦‚æœä½ è¿˜æ²¡æœ‰ä½¿ç”¨ CSS é€‰æ‹©å™¨ï¼Œæˆ‘æœ‰ä¸€ç¯‡ä¸“é—¨çš„åšå®¢æ–‡ç« 
å…³äº[å¦‚ä½•åœ¨æŠ“å–ç½‘é¡µæ—¶ä½¿ç”¨ CSS é€‰æ‹©å™¨](https://serpapi.com/blog/web-scraping-with-css-selectors-using-python/)ï¼Œå®ƒæ¶µç›–äº†ä»€ä¹ˆæ˜¯ CSS é€‰æ‹©å™¨ï¼Œåˆ©å¼Šï¼Œä»¥åŠä¸ºä»€ä¹ˆä»æŠ“å–ç½‘é¡µçš„è§’åº¦æ¥çœ‹å®ƒä»¬å¾ˆé‡è¦ã€‚

**ç‹¬ç«‹çš„è™šæ‹Ÿç¯å¢ƒ**

ç®€è€Œè¨€ä¹‹ï¼Œå®ƒåˆ›å»ºäº†ä¸€ç»„ç‹¬ç«‹çš„å·²å®‰è£…åº“ï¼ŒåŒ…æ‹¬ä¸åŒçš„ Python ç‰ˆæœ¬ï¼Œè¿™äº›ç‰ˆæœ¬å¯ä»¥åœ¨åŒä¸€ç³»ç»Ÿä¸­å…±å­˜ï¼Œä»è€Œé˜²æ­¢åº“æˆ– Python ç‰ˆæœ¬å†²çªã€‚

å¦‚æœä½ ä»¥å‰æ²¡æœ‰ä½¿ç”¨è¿‡è™šæ‹Ÿç¯å¢ƒï¼Œçœ‹çœ‹æˆ‘çš„åšå®¢æ–‡ç« 
ä¸­ä¸“é—¨çš„ [Python è™šæ‹Ÿç¯å¢ƒæ•™ç¨‹ä½¿ç”¨ Virtualenv å’Œ poems](https://serpapi.com/blog/python-virtual-environments-using-virtualenv-and-poetry/)æ¥ç†Ÿæ‚‰ä¸€ä¸‹ã€‚

ğŸ“Œæ³¨æ„:è¿™ä¸æ˜¯è¿™ç¯‡åšæ–‡çš„ä¸¥æ ¼è¦æ±‚ã€‚

**å®‰è£…åº“**:

```
pip install requests parsel
```

**é™ä½è¢«å±è”½çš„å‡ ç‡**

è¯·æ±‚æœ‰å¯èƒ½è¢«é˜»æ­¢ã€‚çœ‹çœ‹[ä¸­çš„
å¦‚ä½•é™ä½æŠ“å–ç½‘é¡µæ—¶è¢«å±è”½çš„å‡ ç‡](https://serpapi.com/blog/how-to-reduce-chance-of-being-blocked-while-web/)ï¼Œæœ‰ 11 ç§æ–¹æ³•å¯ä»¥ç»•è¿‡å¤§å¤šæ•°ç½‘ç«™çš„å±è”½ã€‚

# æŠ“å–è°·æ­Œé‡‘èè‚¡ç¥¨æŠ¥ä»·æ•°æ®

# å…³äºæå–è·‘é©¬ç¯æ•°æ®çš„è¯´æ˜

å¯¼å…¥åº“:

```
import requests, json, re
from parsel import Selector
from itertools import zip_longest
```

*   è¯·æ±‚å‘ç½‘ç«™å‘å‡ºè¯·æ±‚ã€‚
*   å°†æå–çš„æ•°æ®è½¬æ¢æˆ json å¯¹è±¡ã€‚
*   re é€šè¿‡æ­£åˆ™è¡¨è¾¾å¼æå–éƒ¨åˆ†æ•°æ®ã€‚
*   è§£æ HTML/XML æ–‡æ¡£ä¸­çš„æ•°æ®ã€‚ç±»ä¼¼äº BeautifulSoupã€‚
*   zip_longest å¹¶è¡Œè¿­ä»£å¤šä¸ª iterablesã€‚æ›´å¤šä¿¡æ¯è¯·è§ä¸‹æ–‡ã€‚

å®šä¹‰ä¸€ä¸ªå‡½æ•°:

```
def scrape_google_finance(ticker: str): # ticker should be a string
    # further code...scrape_google_finance(ticker="GOOGL:NASDAQ")
```

åˆ›å»ºè¯·æ±‚å¤´å’Œ URL å‚æ•°:

```
# https://docs.python-requests.org/en/master/user/quickstart/#passing-parameters-in-urls
params = {
    "hl": "en" # language
}# https://docs.python-requests.org/en/master/user/quickstart/#custom-headers
# https://www.whatismybrowser.com/detect/what-is-my-user-agent
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.60 Safari/537.36",
}
```

*   [params](https://docs.python-requests.org/en/master/user/quickstart/#passing-parameters-in-urls) å‘è¯·æ±‚ä¼ é€’ URL å‚æ•°çš„ä¸€ç§æ›´æ¼‚äº®çš„æ–¹å¼ã€‚
*   [ç”¨æˆ·ä»£ç†](https://developer.mozilla.org/en-US/docs/Glossary/User_agent)å°†æ¥è‡ªæµè§ˆå™¨çš„â€œçœŸå®â€ç”¨æˆ·è¯·æ±‚ä¼ é€’ç»™[è¯·æ±‚å¤´](https://docs.python-requests.org/en/master/user/quickstart/#custom-headers)ã€‚[æ£€æŸ¥ä½ çš„ç”¨æˆ·ä»£ç†](https://www.whatismybrowser.com/detect/what-is-my-user-agent)ã€‚

ä¼ é€’è¯·æ±‚å‚æ•°å’Œè¯·æ±‚å¤´ï¼Œå‘å‡ºè¯·æ±‚å¹¶å°†å“åº”ä¼ é€’ç»™`parsel`:

```
html = requests.get(f"https://www.google.com/finance/quote/{ticker}", params=params, headers=headers, timeout=30)
selector = Selector(text=html.text)
```

*   f " https://www . Google . com/finance/quote/{ticker} "æ˜¯ä¸€ä¸ª [f å­—ç¬¦ä¸²](https://docs.python.org/3/tutorial/inputoutput.html#fancier-output-formatting)ï¼Œå…¶ä¸­{ ticker }å°†è¢«æ›¿æ¢ä¸ºå®é™…çš„è‚¡ç¥¨ä»£ç å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚" GOOGL:NASDAQ "ã€‚
*   [time out = 30](https://docs.python-requests.org/en/master/user/quickstart/#timeouts)30 ç§’ååœæ­¢ç­‰å¾…å“åº”ã€‚
*   é€‰æ‹©å™¨(text = html . text ), parsel å°†åœ¨å…¶ä¸­å¤„ç†å“åº”ä¸­ä¼ é€’çš„ HTMLã€‚

åˆ›å»ºä¸€ä¸ªç©ºçš„å­—å…¸ç»“æ„ï¼Œå…¶ä¸­å°†å¡«å…¥æ‰€æœ‰æ•°æ®:

```
# where all extracted data will be temporarily located
ticker_data = {
    "ticker_data": {},
    "about_panel": {},
    "news": {"items": []},
    "finance_perfomance": {"table": []}, 
    "people_also_search_for": {"items": []},
    "interested_in": {"items": []}
}
```

æå–å½“å‰ä»·æ ¼ã€æŠ¥ä»·å’Œæ ‡é¢˜æ•°æ®:

```
# current price, quote, title extraction
ticker_data["ticker_data"]["current_price"] = selector.css(".AHmHk .fxKbKc::text").get()
ticker_data["ticker_data"]["quote"] = selector.css(".PdOqHc::text").get().replace(" â€¢ ",":")
ticker_data["ticker_data"]["title"] = selector.css(".zzDege::text").get()
```

*   ticker _ data["ticker_data"]["current_price"]è®¿é—®[" ticker _ data "]é”®ï¼Œåˆ›å»ºä¸€ä¸ªæ–°é”®[" current _ price "]ï¼Œå¹¶å°†å…¶åˆ†é…ç»™ parsel å°†æå–çš„ä»»ä½•å€¼ã€‚æ–°çš„["quote"]å’Œ["title"]å…³é”®å­—ä¹Ÿæ˜¯å¦‚æ­¤ã€‚
*   * text æ˜¯ä¸€ä¸ª [parsel è‡ªå·±çš„ä¼ªå…ƒç´ æ”¯æŒ](https://github.com/scrapy/parsel/blob/90397dcd0b2c1cbb91e44f65c50f9e11628ba028/parsel/csstranslator.py#L48-L51) [ï¼Œå®ƒå°†æŠŠæ¯ä¸ª CSS æŸ¥è¯¢ç¿»è¯‘æˆ XPath](https://github.com/scrapy/parsel/blob/90397dcd0b2c1cbb91e44f65c50f9e11628ba028/parsel/selector.py#L351-L363) ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹::text å°†å˜æˆ/text()ã€‚
*   get() [è·å–å®é™…æ•°æ®](https://github.com/scrapy/parsel/blob/90397dcd0b2c1cbb91e44f65c50f9e11628ba028/parsel/selector.py#L197-L204)ã€‚
*   æ›¿æ¢("ï¼Œ":)[æ¨é™ˆå‡ºæ–°](https://docs.python.org/3/library/stdtypes.html#str.replace)ã€‚

æå–å³é¢æ¿æ•°æ®:

```
about_panel_keys = selector.css(".gyFHrc .mfs7Fc::text").getall()
about_panel_values = selector.css(".gyFHrc .P6K39c").xpath("normalize-space()").getall()for key, value in zip_longest(about_panel_keys, about_panel_values):
    key_value = key.lower().replace(" ", "_")
    ticker_data["about_panel"][key_value] = value
```

*   getall() [è·å–æ‰€æœ‰æ¯”èµ›åˆ—è¡¨](https://github.com/scrapy/parsel/blob/90397dcd0b2c1cbb91e44f65c50f9e11628ba028/parsel/selector.py#L180-L185)ã€‚
*   xpath("normalize-space()") [ä¹Ÿè·å–ç©ºç™½æ–‡æœ¬èŠ‚ç‚¹](https://github.com/scrapy/parsel/issues/62#issuecomment-1042309376)ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œç©ºç™½æ–‡æœ¬èŠ‚ç‚¹å°†è¢«è·³è¿‡ï¼Œå¯¼è‡´ä¸å®Œæ•´çš„è¾“å‡ºã€‚
*   lower() [å°†æ‰€æœ‰å­—ç¬¦ä¸²å­—ç¬¦å°å†™](https://docs.python.org/3/library/stdtypes.html#str.lower)ã€‚
*   zip_longest() [æ¥ç»„åˆå¤šä¸ªè¿­ä»£å™¨](https://docs.python.org/3/library/itertools.html#itertools.zip_longest)ã€‚ [zip()](https://docs.python.org/3/library/functions.html#zip) å’Œ zip_longest()çš„åŒºåˆ«åœ¨äºï¼Œzip()åœ¨æœ€çŸ­çš„è¿­ä»£å™¨å¤„ç»“æŸï¼Œè€Œ [zip_longest()è¿­ä»£åˆ°æœ€é•¿è¿­ä»£å™¨çš„é•¿åº¦](https://stackoverflow.com/questions/59119751/zip-and-zip-longest)ã€‚
*   [key _ value]å°†ä½¿ç”¨å®ƒè‡ªå·±çš„æå–å€¼åŠ¨æ€åœ°å°†ä¸€ä¸ªé”®æ·»åŠ åˆ°å­—å…¸ä¸­ã€‚

ä»å³ä¾§é¢æ¿æå–æè¿°å’Œæ‰©å±•æ•°æ®:

```
# description "about" and  extensions extraction
ticker_data["about_panel"]["description"] = selector.css(".bLLb2d::text").get()
ticker_data["about_panel"]["extensions"] = selector.css(".w2tnNd::text").getall()
```

æå–æ–°é—»ç»“æœ:

```
# news extarction
if selector.css(".yY3Lee").get():
    for index, news in enumerate(selector.css(".yY3Lee"), start=1):
        ticker_data["news"]["items"].append({
            "position": index,
            "title": news.css(".Yfwt5::text").get(),
            "link": news.css(".z4rs2b a::attr(href)").get(),
            "source": news.css(".sfyJob::text").get(),
            "published": news.css(".Adak::text").get(),
            "thumbnail": news.css("img.Z4idke::attr(src)").get()
        })
else: 
    ticker_data["news"]["error"] = f"No news result from a {ticker}."
```

*   if selector.css(".yY3Lee ")ã€‚get()æ£€æŸ¥æ–°é—»ç»“æœæ˜¯å¦å­˜åœ¨ã€‚æ— éœ€æ£€æŸ¥<element>æ˜¯å¦ä¸æ˜¯æ— ã€‚</element>
*   [enumerate()](https://docs.python.org/3/library/functions.html#enumerate) [ç»™ iterable æ·»åŠ ä¸€ä¸ªè®¡æ•°å™¨å¹¶è¿”å›](https://www.programiz.com/python-programming/methods/built-in/enumerate)ã€‚
*   start=1 å°†ä» 1 å¼€å§‹è®¡æ•°ï¼Œè€Œä¸æ˜¯ä»é»˜è®¤å€¼ 0 å¼€å§‹è®¡æ•°ã€‚
*   ticker_data[â€œæ–°é—»â€]ã€‚å°†({})æ·»åŠ åˆ°[å°†](https://docs.python.org/3/tutorial/datastructures.html)æå–çš„æ•°æ®ä½œä¸ºå­—å…¸æ·»åŠ åˆ°åˆ—è¡¨ä¸­ã€‚
*   * attr(src)ä¹Ÿæ˜¯ parsel ä¼ªå…ƒç´ æ”¯æŒï¼Œç”¨äºä»èŠ‚ç‚¹è·å– src å±æ€§ã€‚ç›¸å½“äº XPath /@srcã€‚
*   ticker_data["news"]["error"]åˆ›å»ºä¸€ä¸ªæ–°çš„" error "é”®ï¼Œå¹¶åœ¨é”™è¯¯å‘ç”Ÿæ—¶æ˜¾ç¤ºä¸€æ¡æ¶ˆæ¯ã€‚

æå–è´¢åŠ¡ç»©æ•ˆè¡¨æ•°æ®:

```
# finance perfomance table
# checks if finance table exists
if selector.css(".slpEwd .roXhBd").get():
    fin_perf_col_2 = selector.css(".PFjsMe+ .yNnsfe::text").get()           # e.g. Dec 2021
    fin_perf_col_3 = selector.css(".PFjsMe~ .yNnsfe+ .yNnsfe::text").get()  # e.g. Year/year change

    for fin_perf in selector.css(".slpEwd .roXhBd"):
        if fin_perf.css(".J9Jhg::text , .jU4VAc::text").get():

            """
            if fin_perf.css().get() statement is needed, otherwise first dict key and sub dict values would be None:

            "finance_perfomance": {
            "table": [
                {
                "null": {
                    "Dec 2021": null,
                    "Year/year change": null
                }
            }
            """             

            perf_key = fin_perf.css(".J9Jhg::text , .jU4VAc::text").get()   # e.g. Revenue, Net Income, Operating Income..
            perf_value_col_1 = fin_perf.css(".QXDnM::text").get()           # 60.3B, 26.40%..   
            perf_value_col_2 = fin_perf.css(".gEUVJe .JwB6zf::text").get()  # 2.39%, -21.22%..

            ticker_data["finance_perfomance"]["table"].append({
                perf_key: {
                    fin_perf_col_2: perf_value_col_1, # dynamically add key and value from the second (2) column
                    fin_perf_col_3: perf_value_col_2  # dynamically add key and value from the third (3) column
                }
            })
else:
    ticker_data["finance_perfomance"]["error"] = f"No 'finence perfomance table' for {ticker}."
```

æå–ä½ å¯èƒ½å¾—åˆ°çš„`"interested in"` / `"people also search for"`ç»“æœ:

```
# "you may be interested in" results
    if selector.css(".HDXgAf .tOzDHb").get():
        for index, other_interests in enumerate(selector.css(".HDXgAf .tOzDHb"), start=1):
            ticker_data["interested_in"]["items"].append(discover_more_tickers(index, other_interests))
    else:
        ticker_data["interested_in"]["error"] = f"No 'you may be interested in` results for {ticker}"

    # "people also search for" results
    if selector.css(".HDXgAf+ div .tOzDHb").get():
        for index, other_tickers in enumerate(selector.css(".HDXgAf+ div .tOzDHb"), start=1):
            ticker_data["people_also_search_for"]["items"].append(discover_more_tickers(index, other_tickers))
    else:
        ticker_data["people_also_search_for"]["error"] = f"No 'people_also_search_for` in results for {ticker}"# ....def discover_more_tickers(index: int, other_data: str):
    """
    if price_change_formatted will start complaining,
    check beforehand for None values with try/except or if statement and set it to 0.

    however, re.search(r"\d{1}%|\d{1,10}\.\d{1,2}%" should get the job done.
    """
    return {
            "position": index,
            "ticker": other_data.css(".COaKTb::text").get(),
            "ticker_link": f'https://www.google.com/finance{other_data.attrib["href"].replace("./", "/")}',
            "title": other_data.css(".RwFyvf::text").get(),
            "price": other_data.css(".YMlKec::text").get(),
            "price_change": other_data.css("[jsname=Fe7oBc]::attr(aria-label)").get(),
            # https://regex101.com/r/BOFBlt/1
            # Up by 100.99% -> 100.99%
            "price_change_formatted": re.search(r"\d{1}%|\d{1,10}\.\d{1,2}%", other_data.css("[jsname=Fe7oBc]::attr(aria-label)").get()).group()
        }
```

*   discover_more_tickers()åˆ›å»ºçš„å‡½æ•°ç”¨äºå°†ä¸¤ä¸ªç›¸åŒçš„ä»£ç åˆå¹¶æˆä¸€ä¸ªå‡½æ•°ã€‚è¿™æ ·ï¼Œåªéœ€è¦åœ¨ä¸€ä¸ªåœ°æ–¹ä¿®æ”¹ä»£ç ã€‚
*   [attrib["å±æ€§å"]](https://github.com/scrapy/parsel/blob/90397dcd0b2c1cbb91e44f65c50f9e11628ba028/parsel/selector.py#L209-L215) è·å–èŠ‚ç‚¹å±æ€§ã€‚
*   [jsname=Fe7oBc]æ˜¯ä¸€ä¸ª [CSS é€‰æ‹©å™¨ï¼Œç”¨äºé€‰æ‹©å…·æœ‰æŒ‡å®šå±æ€§å’Œå€¼](https://www.w3schools.com/cssref/sel_attribute_value.asp)çš„å…ƒç´ ï¼Œä¾‹å¦‚[attribute=value]ã€‚
*   re.search()åŒ¹é…éƒ¨åˆ†å­—ç¬¦ä¸²ï¼Œåªè·å–æ•°å­—å’Œ%å€¼ã€‚å’Œ group()é€šè¿‡æ­£åˆ™è¡¨è¾¾å¼è¿”å›åŒ¹é…çš„å­—ç¬¦ä¸²ã€‚

è¿”å›å¹¶æ‰“å°æ•°æ®:

```
# def scrape_google_finance(ticker: str):
    # ticker_data = {
    #     "ticker_data": {},
    #     "about_panel": {},
    #     "news": {"items": []},
    #     "finance_perfomance": {"table": []}, 
    #     "people_also_search_for": {"items": []},
    #     "interested_in": {"items": []}
    # } # extraction code... return ticker_dataprint(json.dumps(data_1, indent=2, ensure_ascii=False))
```

å…¨è¾“å‡º:

# åˆ®å¤šä¸ªè°·æ­Œé‡‘èæŠ¥ä»·

```
for ticker in ["DAX:INDEXDB", "GOOGL:NASDAQ", "MSFT:NASDAQ"]:
    data = scrape_google_finance(ticker=ticker)
    print(json.dumps(data["ticker_data"], indent=2, ensure_ascii=False))
```

äº§å‡º:

```
{
  "current_price": "14,178.23",
  "quote": "DAX:Index",
  "title": "DAX PERFORMANCE-INDEX"
}
{
  "current_price": "$2,665.75",
  "quote": "GOOGL:NASDAQ",
  "title": "Alphabet Inc Class A"
}
{
  "current_price": "$296.97",
  "quote": "MSFT:NASDAQ",
  "title": "Microsoft Corporation"
}
```

# æå–è°·æ­Œè´¢åŠ¡å›¾è¡¨æ—¶é—´åºåˆ—æ•°æ®

æŠ“å–æ—¶é—´åºåˆ—æ•°æ®å¹¶ä¸æ˜¯ä¸€ä¸ªç‰¹åˆ«å¥½çš„ä¸»æ„ï¼Œæ‰€ä»¥æœ€å¥½ä½¿ç”¨ä¸“ç”¨çš„ API æ¥å®Œæˆè¿™é¡¹å·¥ä½œã€‚

å¦‚ä½•æ‰¾åˆ° Google ç”¨å“ªä¸ª API æ¥æ„å»ºæ—¶é—´åºåˆ—å›¾è¡¨ï¼Ÿ

![](img/283653610cd399b5398d38960c28114b.png)

æˆ‘ä»¬å¯ä»¥é€šè¿‡ç®€å•åœ°ç”¨å¼•å· `[GOOGL](https://www.nasdaq.com/market-activity/stocks/googl)`æ£€æŸ¥ [Nasdaq å›¾è¡¨æ¥ç¡®è®¤ Google æ­£åœ¨ä½¿ç”¨ NASDAQ API è·å–æ—¶é—´åºåˆ—æ•°æ®:](https://www.nasdaq.com/market-activity/stocks/googl)

![](img/29a80ec747ccbf14136cabe4dcf26ead.png)

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä½¿ç”¨äº†æ”¯æŒ [Python](https://docs.data.nasdaq.com/docs/python-installation) ã€ [R](https://docs.data.nasdaq.com/docs/r-installation) å’Œ [Excel](https://docs.data.nasdaq.com/docs/excel-installation) çš„[çº³æ–¯è¾¾å…‹æ•°æ®é“¾æ¥ API](https://docs.data.nasdaq.com/) ã€‚æˆ‘ç›¸ä¿¡å…¶ä»–å¹³å°ä¹Ÿæä¾› Python é›†æˆã€‚

æˆ‘å‡è®¾ä½ å·²ç»å®‰è£…äº†ä¸€ä¸ª`nasdaq-data-link`åŒ…ï¼Œä½†æ˜¯å¦‚æœæ²¡æœ‰çš„è¯ï¼Œä½ å¯ä»¥è¿™æ ·åšã€‚å¦‚æœæ‚¨è®¾ç½®äº† Python çš„é»˜è®¤ç‰ˆæœ¬:

```
# WSL
$ pip install nasdaq-data-link
```

å¦‚æœæ‚¨æ²¡æœ‰è®¾ç½® Python çš„é»˜è®¤ç‰ˆæœ¬:

```
# WSL
$ python3.9 -m pip install nasdaq-data-link # change python to your version: python3.X
```

åœ¨`[data.nasdaq.com/account/profile](https://data.nasdaq.com/account/profile)`è·å–æ‚¨çš„ API å¯†é’¥:

![](img/174e5e60f7f2337c15653a5635cb0864.png)

åˆ›å»ºä¸€ä¸ª`.env`æ–‡ä»¶æ¥å­˜å‚¨æ‚¨çš„ API å¯†é’¥:

```
touch .nasdaq_api_key # change the file name to yours # paste API key inside the created file
```

# æŠ“å–è°·æ­Œé‡‘èæ—¶é—´åºåˆ—æ•°æ®

# æ—¶åºæå–ä»£ç è§£é‡Š

*   nasdakdatalink . read _ key(filename =ã€‚nasdaq_api_key") [æ¥è¯»å–ä½ çš„ api å¯†é’¥](https://github.com/Nasdaq/data-link-python#alternative-api-key-file-location)ã€‚
*   ".çº³æ–¯è¾¾å…‹ _api_keyâ€æ˜¯ä½ çš„[ã€‚å¸¦æœ‰ç§˜å¯† API å¯†é’¥çš„ç¯å¢ƒå˜é‡](https://en.wikipedia.org/wiki/Environment_variable#Design)ã€‚æ‰€æœ‰çš„ç§˜å¯†å˜é‡(å¦‚æœæˆ‘é”™äº†ï¼Œè¯·çº æ­£æˆ‘)éƒ½ä»¥ä¸€ä¸ª.ç¬¦å·å¼€å§‹å±•ç¤ºã€‚
*   nasdaqdatalinkã€‚ApiConfig.api_key æ¥æµ‹è¯•æ‚¨çš„ api æ˜¯å¦è¢« nasdaq-data-link åŒ…è¯†åˆ«ã€‚ç¤ºä¾‹è¾“å‡º:2adA_avd12CXauv_1zxs
*   nasdaqdatalink.get()è·å–[æ—¶åºæ•°æ®ï¼Œå³æ•°æ®é›†ç»“æ„](https://github.com/Nasdaq/data-link-python#retrieving-data)ã€‚

è¾“å‡ºä¸€ä¸ª`[pandas](https://pandas.pydata.org/docs/index.html)` `[DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)` [å¯¹è±¡](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html):

```
Open     High      Low    Close      Volume  Ex-Dividend  Split Ratio    Adj. Open    Adj. High     Adj. Low   Adj. Close  Adj. Volume
Date                                                                                                                                                  
2004-08-31   102.320   103.71   102.16   102.37   4917800.0          0.0          1.0    51.318415    52.015567    51.238167    51.343492    4917800.0
2004-09-30   129.899   132.30   129.00   129.60  13758000.0          0.0          1.0    65.150614    66.354831    64.699722    65.000651   13758000.0
2004-10-31   198.870   199.95   190.60   190.64  42282600.0          0.0          1.0    99.742897   100.284569    95.595093    95.615155   42282600.0
2004-11-30   180.700   183.00   180.25   181.98  15384600.0          0.0          1.0    90.629765    91.783326    90.404069    91.271747   15384600.0
2004-12-31   199.230   199.88   192.56   192.79  15321600.0          0.0          1.0    99.923454   100.249460    96.578127    96.693484   15321600.0
...              ...      ...      ...      ...         ...          ...          ...          ...          ...          ...          ...          ...
2017-11-30  1039.940  1044.14  1030.07  1036.17   2190379.0          0.0          1.0  1039.940000  1044.140000  1030.070000  1036.170000    2190379.0
2017-12-31  1055.490  1058.05  1052.70  1053.40   1156357.0          0.0          1.0  1055.490000  1058.050000  1052.700000  1053.400000    1156357.0
2018-01-31  1183.810  1186.32  1172.10  1182.22   1643877.0          0.0          1.0  1183.810000  1186.320000  1172.100000  1182.220000    1643877.0
2018-02-28  1122.000  1127.65  1103.00  1103.92   2431023.0          0.0          1.0  1122.000000  1127.650000  1103.000000  1103.920000    2431023.0
2018-03-31  1063.900  1064.54   997.62  1006.94   2940957.0          0.0          1.0  1063.900000  1064.540000   997.620000  1006.940000    2940957.0[164 rows x 12 columns]
```

å¦‚ä½ æ‰€è§ï¼Œæ²¡æœ‰å…³äº 2019-2022 å¹´çš„æ•°æ®ã€‚æ˜¯å› ä¸ºæˆ‘ç”¨çš„æ˜¯[å…è´¹ç‰ˆï¼Œé€‚åˆå®éªŒæ¢ç´¢ï¼Œçº³æ–¯è¾¾å…‹è¯´](https://docs.data.nasdaq.com/docs/getting-started#free-and-premium-data)ã€‚

# çº³æ–¯è¾¾å…‹åˆ©ç‡é™åˆ¶

ç»è¿‡èº«ä»½éªŒè¯çš„ç”¨æˆ·æ¯ 10 ç§’é’Ÿæœ€å¤šå¯ä»¥æ‰“ 300 ä¸ªç”µè¯ï¼Œæ¯ 10 åˆ†é’Ÿæœ€å¤šå¯ä»¥æ‰“ 2000 ä¸ªç”µè¯ï¼Œæ¯å¤©æœ€å¤šå¯ä»¥æ‰“ 50000 ä¸ªç”µè¯ã€‚é«˜çº§æ•°æ®ç”¨æˆ·æ¯ 10 åˆ†é’Ÿæœ€å¤šå¯æ‹¨æ‰“ 5000 æ¬¡ç”µè¯ï¼Œæ¯å¤©æœ€å¤šå¯æ‹¨æ‰“ 720000 æ¬¡ç”µè¯ã€‚

# å…¶ä»–çº³æ–¯è¾¾å…‹ API èµ„æº

*   [æ—¶åºå‚æ•°](https://docs.data.nasdaq.com/docs/parameters-2)é€šè¿‡å‘è¯·æ±‚æ·»åŠ é¢å¤–çš„å‚æ•°æ¥å®šåˆ¶(æ“ä½œ)æ‚¨çš„æ—¶åºæ•°æ®é›†ã€‚[æ—¶é—´åºåˆ—æ•°æ®çš„è½¬æ¢](https://docs.data.nasdaq.com/docs/parameters-2#transformations)ã€‚
*   [ä½¿ç”¨ curl ç¼–å†™è¯·æ±‚](https://docs.data.nasdaq.com/docs/quick-start-examples-1)ä½¿ç”¨ curl è½»æ¾å‘å‡ºè¯·æ±‚ã€‚
*   [å¯ç”¨çš„ä¿å­˜æ ¼å¼](https://blog.data.nasdaq.com/getting-started-with-the-nasdaq-data-link-api)ä»¥ CSVã€XMLã€JSON æ ¼å¼ä¿å­˜æ•°æ®ã€‚
*   [æ•°æ®æ ¼å¼](https://github.com/Nasdaq/data-link-python/blob/main/FOR_DEVELOPERS.md#data-formats)å°†æ•°æ®è½¬æ¢æˆå¯ç”¨çš„æ ¼å¼ã€‚
*   [æ‰¹é‡ä¸‹è½½](https://github.com/Nasdaq/data-link-python/blob/main/FOR_ANALYSTS.md#download-entire-database-bulk-download)ä¸€æ¬¡è°ƒç”¨å³å¯ä¸‹è½½æ•°æ®åº“ä¸­çš„æ‰€æœ‰æ•°æ®ã€‚
*   [å¯ç”¨æ–¹æ³•çš„è¯¦ç»†æŒ‡å—](https://github.com/Nasdaq/data-link-python/blob/main/FOR_DEVELOPERS.md#detailed-method-guide---nasdaq-data-linkpython)æ›´è¯¦ç»†åœ°äº†è§£å¦‚ä½•ä½¿ç”¨ data-link-python åŒ…ã€‚
*   [GitHub ä¸Šçš„ data-link-python](https://github.com/Nasdaq/data-link-python)é˜…è¯»å®Œæ•´æ–‡æ¡£ã€‚
*   GitHub ä¸Šçš„ quandl-python çœ‹çœ‹ data-link-python åœ¨å¹•åä½¿ç”¨çš„æ˜¯ä»€ä¹ˆã€‚ä½ å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°æ›´å¤šçš„æ–‡æ¡£ã€‚

# é“¾æ¥

*   [åœ¨çº¿ IDE ä¸­çš„ä»£ç ](https://replit.com/@DimitryZub1/Scrape-Google-Finance-Ticker-Quote-in-Python#main.py)
*   [GitHub åº“](https://github.com/dimitryzub/google-finance-py/tree/main)

# ç»“å°¾éƒ¨åˆ†

å¦‚æœä½ æœ‰ä»»ä½•è¦åˆ†äº«çš„ä¸œè¥¿ï¼Œä»»ä½•é—®é¢˜ï¼Œå»ºè®®ï¼Œæˆ–ä¸€äº›ä¸èƒ½æ­£å¸¸å·¥ä½œçš„äº‹æƒ…ï¼Œè¯·é€šè¿‡ Twitter è”ç³»æˆ‘ä»¬ï¼Œåœ°å€æ˜¯ [@dimitryzub](https://twitter.com/DimitryZub) æˆ– [@serp_api](https://twitter.com/serp_api) ã€‚

ä½ çš„ï¼Œ
å¾·ç±³ç‰¹é‡Œï¼Œè¿˜æœ‰å¡å°”å¸•çš®å›¢é˜Ÿçš„å…¶ä»–äººã€‚

åœ¨æ¨ç‰¹[ä¸ŠåŠ å…¥ SerpApi](https://twitter.com/serp_api)|[YouTube](https://www.youtube.com/channel/UCUgIHlYBOD3yA3yDIRhg_mg)

æ·»åŠ ä¸€ä¸ª[ç‰¹å¾è¯·æ±‚](https://github.com/serpapi/SerpApi/issues/)ğŸ’«è¿˜æ˜¯ä¸€ä¸ª [Bug](https://github.com/serpapi/SerpApi/issues/) ğŸ