# Windows ç¯å¢ƒä¸‹åŸºäº OpenCV-DNN-CUDA çš„ YOLOv4 æ¨ç†

> åŸæ–‡ï¼š<https://medium.com/geekculture/yolov4-inference-using-opencv-dnn-cuda-on-windows-e7ca995bcacd?source=collection_archive---------5----------------------->

![](img/12f64343ceb8f4f91a530e80c3950431.png)

# åœ¨ Windows ä¸Šä½¿ç”¨ OpenCV-DNN-CUDA æ¨¡å—è¿è¡Œ YOLOv4 æ¨ç†ã€‚

åœ¨ä¹‹å‰çš„åšå®¢[â€œè®¾ç½®æ”¯æŒ CUDA åç«¯çš„ OpenCV-DNN æ¨¡å—(ç”¨äº Windows)â€](https://techzizou.com/setup-opencv-dnn-cuda-module-for-windows/)ä¸­ï¼Œæˆ‘ä»¬åœ¨ Windows ä¸Šæ„å»ºäº†æ”¯æŒ CUDA åç«¯çš„ OpenCV-DNN æ¨¡å—ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ä¸ª OpenCV æ¨¡å—åœ¨å¯¹è±¡æ£€æµ‹æ¨¡å‹ä¸Šè¿è¡Œæ¨ç†ã€‚ä¸æ²¡æœ‰ CUDA åç«¯çš„ OpenCV ç›¸æ¯”ï¼Œä½¿ç”¨ CUDA åç«¯æ”¯æŒæ„å»ºçš„ OpenCV-DNN æ¨¡å—ç»™å‡ºäº†æ›´å¿«çš„æ¨æ–­ã€‚æˆ‘ä»¬éœ€è¦åšçš„å°±æ˜¯å°†ä¸‹é¢ä¸¤è¡Œä»£ç æ·»åŠ åˆ°æˆ‘ä»¬çš„ä»£ç ä¸­ï¼Œå¹¶ä½¿ç”¨å®ƒæ¥æ¨æ–­æ¨¡å‹ã€‚

```
net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)
net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)
```

æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤ï¼Œä½¿ç”¨æˆ‘ä»¬å®‰è£…çš„ OpenCV-DNN-CUDA æ¨¡å—è¿è¡Œæ¨ç†:

*   é¦–å…ˆï¼Œæ‰“å¼€ Anaconda æç¤ºç¬¦å¹¶æ¿€æ´»æ‚¨ç”¨æ¥å®‰è£… OpenCV-DNN-CUDA æ¨¡å—çš„è™šæ‹Ÿç¯å¢ƒã€‚
*   æ¥ä¸‹æ¥ï¼Œä¸‹è½½ä¸‹é¢çš„ python *opencv_dnn.py* è„šæœ¬å¹¶ä½¿ç”¨ python è¿è¡Œå®ƒã€‚è¯·æ³¨æ„ï¼Œè¿™ä½¿ç”¨äº† yolov4 æ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶ã€‚ä»[è¿™é‡Œ](https://github.com/AlexeyAB/darknet)ä¸‹è½½ã€‚

```
import cv2
import timeCONFIDENCE_THRESHOLD = 0.2
NMS_THRESHOLD = 0.4
COLORS = [(0, 255, 255), (255, 255, 0), (0, 255, 0), (255, 0, 0)]class_names = []
with open("classes.txt", "r") as f:
    class_names = [cname.strip() for cname in f.readlines()]cap = cv2.VideoCapture("video.mp4")net = cv2.dnn.readNet("yolov4.weights", "yolov4.cfg")
net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)
net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA_FP16)model = cv2.dnn_DetectionModel(net)
model.setInputParams(size=(416, 416), scale=1/255, swapRB=True)while cv2.waitKey(1) < 1:
    (grabbed, frame) = cap.read()
    if not grabbed:
        exit() start = time.time()
    classes, scores, boxes = model.detect(frame, CONFIDENCE_THRESHOLD, NMS_THRESHOLD)
    end = time.time() for (classid, score, box) in zip(classes, scores, boxes):
        color = COLORS[int(classid) % len(COLORS)]
        label = "%s : %f" % (class_names[classid[0]], score)
        cv2.rectangle(frame, box, color, 2)
        cv2.putText(frame, label, (box[0], box[1]-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    fps = "FPS: %.2f " % (1 / (end - start))
    cv2.putText(frame, fps, (0, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2)
    cv2.imshow("output", frame)
```

åœ¨è¿™é‡Œä¸‹è½½ä¸Šé¢çš„è„šæœ¬æ¥æµ‹è¯• OpenCV-DNN æ¨ç†ã€‚

[**ä¸‹è½½ opencv_dnn.py**](https://techzizou.com/yolov4-inference-using-opencv-dnn-cuda-on-windows/#opencv_dnn_windows)

**é‡è¦æç¤º:**OpenCV-DNN-CUDA æ¨¡å—åªæ”¯æŒæ¨ç†ã€‚å› æ­¤ï¼Œè™½ç„¶ä½ ä¼šä»ä¸­è·å¾—æ›´å¿«çš„æ¨ç†ï¼Œä½†è®­ç»ƒå°†ä¸æˆ‘ä»¬åœ¨æ²¡æœ‰ CUDA åç«¯æ”¯æŒçš„æƒ…å†µä¸‹è®¾ç½®çš„ OpenCV ç›¸åŒã€‚

æ‚¨è¿˜å¯ä»¥ä½¿ç”¨ OpenCV-DNN-CUDA æ¨¡å—å¯¹æ¥è‡ª TensorFlowã€PyTorch ç­‰å„ç§å…¶ä»–æ¡†æ¶çš„æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚

# æˆ‘åœ¨ YouTube ä¸Šçš„è§†é¢‘ï¼

# ä¹‹å‰çš„æ•™ç¨‹:

## ä½¿ç”¨ CUDA åç«¯æ”¯æŒè®¾ç½® OpenCV-DNN æ¨¡å—(é€‚ç”¨äº Windows)

[](https://techzizou007.medium.com/setup-opencv-dnn-module-with-cuda-backend-support-for-windows-7f1856691da3) [## ä½¿ç”¨ CUDA åç«¯æ”¯æŒè®¾ç½® OpenCV-DNN æ¨¡å—(é€‚ç”¨äº Windows)

### åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ CUDA åç«¯æ”¯æŒä»æºä»£ç æ„å»º OpenCV(OpenCV-DNN-CUDA æ¨¡å—)ã€‚

techzizou007.medium.com](https://techzizou007.medium.com/setup-opencv-dnn-module-with-cuda-backend-support-for-windows-7f1856691da3) 

## åˆ«å¿˜äº†ç•™ä¸‹ğŸ‘

## ç¥æ‚¨æ„‰å¿«ï¼ï¼ï¼âœŒ

# â™•Â·ç‰¹å¥‡ä½Â·â™•